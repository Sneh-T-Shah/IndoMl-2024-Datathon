{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9642895,"sourceType":"datasetVersion","datasetId":5779523},{"sourceId":9722369,"sourceType":"datasetVersion","datasetId":5920554}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":17291.373492,"end_time":"2024-10-21T16:02:46.593181","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-21T11:14:35.219689","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"041ee7fad21d42b5b19fb4758387adb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0514a8aa63b440439821f09baf14bf7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"076d2567f10c4c98bf27916b3cb67d7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_893f9114241542f8905c81e80ea3890a","max":1115567652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48bff578f00a49d29c86714366c899a2","value":1115567652}},"0a5db372173b4e5ca80f181321b9cad4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d16402e18f4ef09dd070d998b8a705","placeholder":"​","style":"IPY_MODEL_11a352d00a2d4322979719f25eaf9f49","value":"tokenizer.json: 100%"}},"0df710dab74d4265879a524c3295724b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e80044f31c54fa5a0b0a4669c114d40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"118b5a9fde9c4af6acff246074164583":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5a8c910020c4b6a90cd3e47c12c3592","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e80044f31c54fa5a0b0a4669c114d40","value":25}},"11a352d00a2d4322979719f25eaf9f49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1238893a71114d8085921306f2d8e781":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e88a10001ae442a9fd104e6658868c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"237cfddaa78642f78e1b924f3093c2d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_788490c37f41428caebf2589e324c55e","placeholder":"​","style":"IPY_MODEL_422ca79960b94886b516aafa07ae9c87","value":" 615/615 [00:00&lt;00:00, 59.2kB/s]"}},"3103af50d1fc41ddaa72a898b237bdad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36fed59169b146b0b7e884585eb951e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d322291e4ea45cfa3de466c6a29e618","IPY_MODEL_3acfb003fb5a48459feb08decd2d4b04","IPY_MODEL_237cfddaa78642f78e1b924f3093c2d3"],"layout":"IPY_MODEL_a1ad76be88cf41cc8f500e0b8beeae12"}},"3acfb003fb5a48459feb08decd2d4b04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df7112c9ae2d4ab5a4932abb9a67c8cb","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8876708c1db64e1da580da7589a0a82f","value":615}},"3d322291e4ea45cfa3de466c6a29e618":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd842d67e2804230b1be730df87a71ef","placeholder":"​","style":"IPY_MODEL_569eb9be6bc7477aac6e5e7b3095e1f8","value":"config.json: 100%"}},"422ca79960b94886b516aafa07ae9c87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"441755408e1042bf87ca8241dc1c601f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e49c4957c74347e0beffa4222cb477cd","placeholder":"​","style":"IPY_MODEL_9f8043d7fbbb4b64a23ce3062c609a0d","value":"tokenizer_config.json: 100%"}},"48bff578f00a49d29c86714366c899a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5397fab8febd4a06885b7e925ad5ff2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569eb9be6bc7477aac6e5e7b3095e1f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60252148b70241c5bd3a1c367f109bf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"672b9451e7ff4920a62c735fd4ab2734":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68ab3c6c41d740629dcf6879940cd0e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_441755408e1042bf87ca8241dc1c601f","IPY_MODEL_118b5a9fde9c4af6acff246074164583","IPY_MODEL_e66df11a28fe4e7c9ea0d566fcd81137"],"layout":"IPY_MODEL_9ec43d4dd2df408d95f42ac72c984f2e"}},"68f61c96e2a04f1a8b6bd8d23fc3ff25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5397fab8febd4a06885b7e925ad5ff2d","placeholder":"​","style":"IPY_MODEL_672b9451e7ff4920a62c735fd4ab2734","value":" 1.12G/1.12G [00:03&lt;00:00, 315MB/s]"}},"758c72e5fc1c42b0a42c911034dcec3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"788490c37f41428caebf2589e324c55e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d61abe3b3074ef983d0582a42e7ab03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f47baf80b784f169cc329313350e889":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"836b42c9f956406bb3bea6c9abd7af03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aafd93aa8df349028e7138659d7dca1d","placeholder":"​","style":"IPY_MODEL_8fe43ab7a92c4689b1f30e224c000a0d","value":" 9.10M/9.10M [00:00&lt;00:00, 27.8MB/s]"}},"8876708c1db64e1da580da7589a0a82f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"893f9114241542f8905c81e80ea3890a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fe43ab7a92c4689b1f30e224c000a0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95da8b6525774a1b94b003412b5b10be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db5ff17b6fa248e8a7dfe20207560c7f","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7185ac3dd1043d18d308b1e706f1573","value":9096718}},"9ec43d4dd2df408d95f42ac72c984f2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f8043d7fbbb4b64a23ce3062c609a0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1ad76be88cf41cc8f500e0b8beeae12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7a7ed8e8a7a4c418905cc108b014125":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9dfd756e08a439e8f56046f969908ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f57ff580f6db48de9aa35c96c5ebd17d","IPY_MODEL_aee2bee5ca3c4e1585f99fc4e4a0f3de","IPY_MODEL_b2609302e23d40d18dc7525ed9e563c9"],"layout":"IPY_MODEL_7f47baf80b784f169cc329313350e889"}},"aad24f61b97b41358efb1c366b1a0112":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb956d0c6aad408baccd8fb6c589f05a","IPY_MODEL_076d2567f10c4c98bf27916b3cb67d7c","IPY_MODEL_68f61c96e2a04f1a8b6bd8d23fc3ff25"],"layout":"IPY_MODEL_0df710dab74d4265879a524c3295724b"}},"aafd93aa8df349028e7138659d7dca1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee2bee5ca3c4e1585f99fc4e4a0f3de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e88a10001ae442a9fd104e6658868c0","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d61abe3b3074ef983d0582a42e7ab03","value":5069051}},"b230d4158ad747e490b5b4c276e319c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2609302e23d40d18dc7525ed9e563c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1238893a71114d8085921306f2d8e781","placeholder":"​","style":"IPY_MODEL_758c72e5fc1c42b0a42c911034dcec3d","value":" 5.07M/5.07M [00:00&lt;00:00, 19.1MB/s]"}},"b7185ac3dd1043d18d308b1e706f1573":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5a8c910020c4b6a90cd3e47c12c3592":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd842d67e2804230b1be730df87a71ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3f3e92eac454a04af4b1c35769c4012":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a5db372173b4e5ca80f181321b9cad4","IPY_MODEL_95da8b6525774a1b94b003412b5b10be","IPY_MODEL_836b42c9f956406bb3bea6c9abd7af03"],"layout":"IPY_MODEL_3103af50d1fc41ddaa72a898b237bdad"}},"d81a8327282146e28182c700d5990a44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db5ff17b6fa248e8a7dfe20207560c7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df7112c9ae2d4ab5a4932abb9a67c8cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e49c4957c74347e0beffa4222cb477cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e66df11a28fe4e7c9ea0d566fcd81137":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7a7ed8e8a7a4c418905cc108b014125","placeholder":"​","style":"IPY_MODEL_041ee7fad21d42b5b19fb4758387adb8","value":" 25.0/25.0 [00:00&lt;00:00, 1.88kB/s]"}},"e8d16402e18f4ef09dd070d998b8a705":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb956d0c6aad408baccd8fb6c589f05a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b230d4158ad747e490b5b4c276e319c6","placeholder":"​","style":"IPY_MODEL_60252148b70241c5bd3a1c367f109bf9","value":"model.safetensors: 100%"}},"f57ff580f6db48de9aa35c96c5ebd17d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d81a8327282146e28182c700d5990a44","placeholder":"​","style":"IPY_MODEL_0514a8aa63b440439821f09baf14bf7e","value":"sentencepiece.bpe.model: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sklearn.metrics import accuracy_score\n\ndf_features = pd.read_json('/kaggle/input/indoml-phase2/train.features',lines=True)\ndf_labels = pd.read_json('/kaggle/input/indoml-phase2/train.labels',lines=True)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-10-21T16:41:11.860221Z","iopub.execute_input":"2024-10-21T16:41:11.860574Z","iopub.status.idle":"2024-10-21T16:41:22.458808Z","shell.execute_reply.started":"2024-10-21T16:41:11.860537Z","shell.execute_reply":"2024-10-21T16:41:22.457867Z"},"papermill":{"duration":10.832945,"end_time":"2024-10-21T11:14:48.768505","exception":false,"start_time":"2024-10-21T11:14:37.935560","status":"completed"},"tags":[],"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nhuggingface_token = \"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\"\nlogin(token=huggingface_token)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:22.460315Z","iopub.execute_input":"2024-10-21T16:41:22.460650Z","iopub.status.idle":"2024-10-21T16:41:22.997826Z","shell.execute_reply.started":"2024-10-21T16:41:22.460617Z","shell.execute_reply":"2024-10-21T16:41:22.996745Z"},"papermill":{"duration":0.55105,"end_time":"2024-10-21T11:14:49.330121","exception":false,"start_time":"2024-10-21T11:14:48.779071","status":"completed"},"tags":[],"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.merge(df_features,df_labels,on=\"indoml_id\")","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:22.999114Z","iopub.execute_input":"2024-10-21T16:41:22.999519Z","iopub.status.idle":"2024-10-21T16:41:23.152808Z","shell.execute_reply.started":"2024-10-21T16:41:22.999466Z","shell.execute_reply":"2024-10-21T16:41:23.151856Z"},"papermill":{"duration":0.167323,"end_time":"2024-10-21T11:14:49.508024","exception":false,"start_time":"2024-10-21T11:14:49.340701","status":"completed"},"tags":[],"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# df = df[:1000]","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:23.155310Z","iopub.execute_input":"2024-10-21T16:41:23.156079Z","iopub.status.idle":"2024-10-21T16:41:23.160346Z","shell.execute_reply.started":"2024-10-21T16:41:23.156031Z","shell.execute_reply":"2024-10-21T16:41:23.159396Z"},"papermill":{"duration":0.017056,"end_time":"2024-10-21T11:14:49.535857","exception":false,"start_time":"2024-10-21T11:14:49.518801","status":"completed"},"tags":[],"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ngroup_encoder = LabelEncoder()\nsupergroup_encoder = LabelEncoder()\nmodule_encoder = LabelEncoder()\nbrand_encoder = LabelEncoder()\n\n# Fit and transform each column\ndf['group'] = group_encoder.fit_transform(df['group'])\ndf['supergroup'] = supergroup_encoder.fit_transform(df['supergroup'])\ndf['module'] = module_encoder.fit_transform(df['module'])\ndf['brand'] = brand_encoder.fit_transform(df['brand'])\ndf['description'] = df['description'] + df['retailer']","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:23.161597Z","iopub.execute_input":"2024-10-21T16:41:23.161919Z","iopub.status.idle":"2024-10-21T16:41:23.205890Z","shell.execute_reply.started":"2024-10-21T16:41:23.161853Z","shell.execute_reply":"2024-10-21T16:41:23.205032Z"},"papermill":{"duration":0.85631,"end_time":"2024-10-21T11:14:50.402587","exception":false,"start_time":"2024-10-21T11:14:49.546277","status":"completed"},"tags":[],"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, XLMRobertaModel\n# from transformers import XLNetTokenizer, XLNetModel\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score\nfrom torch.distributions import Categorical\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:23.206926Z","iopub.execute_input":"2024-10-21T16:41:23.207256Z","iopub.status.idle":"2024-10-21T16:41:24.709541Z","shell.execute_reply.started":"2024-10-21T16:41:23.207223Z","shell.execute_reply":"2024-10-21T16:41:24.708419Z"},"papermill":{"duration":1.704383,"end_time":"2024-10-21T11:14:52.117645","exception":false,"start_time":"2024-10-21T11:14:50.413262","status":"completed"},"tags":[],"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# For using the new one\n# tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n\n# For loading the saved one\nmodel_dir = \"/kaggle/input/new-transformer-experiment-12-emb-xlm-roberta-tmp/New_model\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:24.710870Z","iopub.execute_input":"2024-10-21T16:41:24.711365Z","iopub.status.idle":"2024-10-21T16:41:25.693290Z","shell.execute_reply.started":"2024-10-21T16:41:24.711328Z","shell.execute_reply":"2024-10-21T16:41:25.692269Z"},"papermill":{"duration":3.044988,"end_time":"2024-10-21T11:14:55.173317","exception":false,"start_time":"2024-10-21T11:14:52.128329","status":"completed"},"tags":[],"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 12\nBATCH_SIZE = 64\nLEARNING_RATE = 5e-5\nNUM_EPOCHS = 14\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice=DEVICE\nPATIENCE = 5  # Early stopping patience\nPATIENCE_LR = 3  # Reduce LR on plateau patience","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:25.694546Z","iopub.execute_input":"2024-10-21T16:41:25.694938Z","iopub.status.idle":"2024-10-21T16:41:25.729269Z","shell.execute_reply.started":"2024-10-21T16:41:25.694895Z","shell.execute_reply":"2024-10-21T16:41:25.728334Z"},"papermill":{"duration":0.079725,"end_time":"2024-10-21T11:14:55.264453","exception":false,"start_time":"2024-10-21T11:14:55.184728","status":"completed"},"tags":[],"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:25.730747Z","iopub.execute_input":"2024-10-21T16:41:25.731078Z","iopub.status.idle":"2024-10-21T16:41:25.738133Z","shell.execute_reply.started":"2024-10-21T16:41:25.731045Z","shell.execute_reply":"2024-10-21T16:41:25.737262Z"},"papermill":{"duration":0.017895,"end_time":"2024-10-21T11:14:55.293581","exception":false,"start_time":"2024-10-21T11:14:55.275686","status":"completed"},"tags":[],"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ProductDataset(Dataset):\n    \n    def __init__(self, texts, labels1, labels2, labels3, labels4):\n        self.texts = texts\n        self.labels1 = labels1\n        self.labels2 = labels2\n        self.labels3 = labels3\n        self.labels4 = labels4\n        self.encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\")\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        item = {key: val[idx].to(DEVICE) for key, val in self.encodings.items()}\n        item['labels1'] = torch.tensor(self.labels1[idx], device=DEVICE)\n        item['labels2'] = torch.tensor(self.labels2[idx], device=DEVICE)\n        item['labels3'] = torch.tensor(self.labels3[idx], device=DEVICE)\n        item['labels4'] = torch.tensor(self.labels4[idx], device=DEVICE)\n        return item\n\ndef compute_accuracy(preds, labels):\n    # Convert each tensor in the list to numpy arrays\n    preds_np = [p.cpu().numpy() for p in preds]\n    labels_np = [l.cpu().numpy() for l in labels]\n    # Individual accuracies for each of the 4 labels\n    accuracies = [accuracy_score(labels_np[i], preds_np[i]) for i in range(4)]\n    # Overall accuracy where all 4 labels match\n    overall_accuracy = accuracy_score(\n        np.all([labels_np[i] == preds_np[i] for i in range(4)], axis=0), \n        np.ones(len(labels_np[0]))\n    )\n    # Return the 5 accuracies (4 individual, 1 overall)\n    return accuracies + [overall_accuracy]","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:25.741725Z","iopub.execute_input":"2024-10-21T16:41:25.742080Z","iopub.status.idle":"2024-10-21T16:41:25.754362Z","shell.execute_reply.started":"2024-10-21T16:41:25.742048Z","shell.execute_reply":"2024-10-21T16:41:25.753541Z"},"papermill":{"duration":0.024408,"end_time":"2024-10-21T11:14:55.328924","exception":false,"start_time":"2024-10-21T11:14:55.304516","status":"completed"},"tags":[],"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Split data\ntrain_texts, val_texts, train_labels1, val_labels1, train_labels2, val_labels2, train_labels3, val_labels3, train_labels4, val_labels4 = train_test_split(\n    df['description'], \n    df['supergroup'], \n    df['group'], \n    df['module'], \n    df['brand'], \n    test_size=0.2, \n    random_state=42\n)\ntrain_dataset = ProductDataset(\n    train_texts.tolist(), \n    train_labels1.tolist(), \n    train_labels2.tolist(), \n    train_labels3.tolist(), \n    train_labels4.tolist()\n)\nval_dataset = ProductDataset(\n    val_texts.tolist(), \n    val_labels1.tolist(), \n    val_labels2.tolist(), \n    val_labels3.tolist(), \n    val_labels4.tolist()\n)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:25.755450Z","iopub.execute_input":"2024-10-21T16:41:25.755828Z","iopub.status.idle":"2024-10-21T16:41:25.819537Z","shell.execute_reply.started":"2024-10-21T16:41:25.755797Z","shell.execute_reply":"2024-10-21T16:41:25.818538Z"},"papermill":{"duration":23.105017,"end_time":"2024-10-21T11:15:18.444849","exception":false,"start_time":"2024-10-21T11:14:55.339832","status":"completed"},"tags":[],"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# from transformers import DebertaModel, DebertaTokenizer\nfrom transformers import XLNetTokenizer, XLMRobertaModel\nfrom torch.distributions import Categorical\nimport os\n\nclass AdvancedHierarchicalClassifier(nn.Module):\n    def __init__(self, num_supergroups, num_groups, num_modules, num_brands, hidden_size=768, projection_dim=128):\n        super().__init__()\n        # For loading the new model\n        # self.model = XLNetModel.from_pretrained('xlnet-base-cased')\n        self.model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n        self.hidden_size = hidden_size\n        # Classifiers for each hierarchy level\n        self.supergroup_classifier = nn.Linear(hidden_size, num_supergroups)\n        self.group_classifier = nn.Linear(hidden_size + num_supergroups, num_groups)\n        self.module_classifier = nn.Linear(hidden_size + num_supergroups + num_groups, num_modules)\n        self.brand_classifier = nn.Linear(hidden_size + num_supergroups + num_groups + num_modules, num_brands)\n        # RL Policy networks for each level\n        self.supergroup_policy = nn.Linear(hidden_size, num_supergroups)\n        self.group_policy = nn.Linear(hidden_size + num_supergroups, num_groups)\n        self.module_policy = nn.Linear(hidden_size + num_supergroups + num_groups, num_modules)\n        self.brand_policy = nn.Linear(hidden_size + num_supergroups + num_groups + num_modules, num_brands)\n        # Contrastive learning projection head\n        self.projection = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, projection_dim)\n        )\n        # Few-shot learning prototypes\n        self.prototypes = nn.Parameter(torch.randn(num_supergroups + num_groups + num_modules + num_brands, hidden_size))\n   \n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_states = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n        # Supervised classification logits\n        supergroup_logits = self.supergroup_classifier(hidden_states)\n        group_input = torch.cat([hidden_states, torch.softmax(supergroup_logits, dim=1)], dim=1)\n        group_logits = self.group_classifier(group_input)\n        module_input = torch.cat([group_input, torch.softmax(group_logits, dim=1)], dim=1)\n        module_logits = self.module_classifier(module_input)\n        brand_input = torch.cat([module_input, torch.softmax(module_logits, dim=1)], dim=1)\n        brand_logits = self.brand_classifier(brand_input)\n        # RL policy logits\n        supergroup_policy = self.supergroup_policy(hidden_states)\n        group_policy = self.group_policy(group_input)\n        module_policy = self.module_policy(module_input)\n        brand_policy = self.brand_policy(brand_input)\n        # Contrastive learning projection\n        projection = self.projection(hidden_states)\n        # Few-shot learning\n        prototype_distances = torch.cdist(hidden_states, self.prototypes)\n        few_shot_logits = -prototype_distances  # Negative distance as logits\n        return (supergroup_logits, group_logits, module_logits, brand_logits), \\\n               (supergroup_policy, group_policy, module_policy, brand_policy), \\\n               projection, few_shot_logits\n   \n    def sample_actions(self, policies):\n        return [Categorical(logits=policy).sample() for policy in policies]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class JointAccuracyTrainer:\n#     def __init__(self, model, supervised_lr=1e-5, rl_lr=1e-4, contrastive_temperature=0.07, loss_weights=None):\n#         self.model = model\n#         self.device = next(model.parameters()).device  # Get the device from the model's parameters\n#         self.supervised_optimizer = torch.optim.NAdam(model.parameters(), lr=supervised_lr)\n#         self.rl_optimizer = torch.optim.NAdam(model.parameters(), lr=rl_lr)\n#         self.criterion = nn.CrossEntropyLoss()\n#         self.contrastive_temperature = contrastive_temperature\n#         if loss_weights is None:\n#             self.loss_weights = [1.0, 1.0, 1.0, 1.0]\n#         else:\n#             self.loss_weights = loss_weights\n  \n#     def compute_joint_loss(self, all_outputs, true_labels):\n#         # Unpack the model outputs\n#         supervised_logits, policy_logits, projection, few_shot_logits = all_outputs\n#         logits_supergroup, logits_group1, logits_group2, logits_group3 = supervised_logits\n#         # Compute classification losses for all levels\n#         loss_supergroup = self.criterion(logits_supergroup, true_labels['supergroup'])\n#         loss_group1 = self.criterion(logits_group1, true_labels['group1'])\n#         loss_group2 = self.criterion(logits_group2, true_labels['group2'])\n#         loss_group3 = self.criterion(logits_group3, true_labels['group3'])\n#         # Combine losses using weighted sum\n#         total_loss = (\n#             self.loss_weights[0] * loss_supergroup + \n#             self.loss_weights[1] * loss_group1 + \n#             self.loss_weights[2] * loss_group2 + \n#             self.loss_weights[3] * loss_group3\n#         )\n#         return total_loss\n  \n#     def supervised_step(self, batch, true_labels):\n#         self.supervised_optimizer.zero_grad()\n#         # Forward pass through the model\n#         all_outputs = self.model(batch['input_ids'], batch['attention_mask'])\n#         # Compute joint loss for all levels\n#         total_loss = self.compute_joint_loss(all_outputs, true_labels)\n#         # Backpropagate and update model weights\n#         total_loss.backward()\n#         torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n#         self.supervised_optimizer.step()\n#         return total_loss.item()\n#     def validation_step(self, batch, true_labels):\n#         with torch.no_grad():\n#             # Forward pass during validation\n#             all_outputs = self.model(batch['input_ids'], batch['attention_mask'])\n#             supervised_logits, _, _, _ = all_outputs\n#             logits_supergroup, logits_group1, logits_group2, logits_group3 = supervised_logits\n#             # Compute predictions\n#             preds_supergroup = torch.argmax(logits_supergroup, dim=-1)\n#             preds_group1 = torch.argmax(logits_group1, dim=-1)\n#             preds_group2 = torch.argmax(logits_group2, dim=-1)\n#             preds_group3 = torch.argmax(logits_group3, dim=-1)\n#             # Compute accuracies\n#             supergroup_acc = (preds_supergroup == true_labels['supergroup']).float().mean().item()\n#             group1_acc = (preds_group1 == true_labels['group1']).float().mean().item()\n#             group2_acc = (preds_group2 == true_labels['group2']).float().mean().item()\n#             group3_acc = (preds_group3 == true_labels['group3']).float().mean().item()\n#             # Joint accuracy\n#             item_acc = ((preds_supergroup == true_labels['supergroup']) &\n#                        (preds_group1 == true_labels['group1']) &\n#                        (preds_group2 == true_labels['group2']) &\n#                        (preds_group3 == true_labels['group3'])).float().mean().item()\n#         return supergroup_acc, group1_acc, group2_acc, group3_acc, item_acc\n# def train_and_evaluate(model, train_loader, val_loader, num_epochs=10):\n#     trainer = JointAccuracyTrainer(model)\n#     for epoch in range(num_epochs):\n#         model.train()\n#         total_sup_loss = 0.0\n#         # Training loop\n#         for batch in train_loader:\n#             batch = {k: v.to(device) for k, v in batch.items()}\n#             true_labels = {\n#                 'supergroup': batch['labels1'],\n#                 'group1': batch['labels2'],\n#                 'group2': batch['labels3'],\n#                 'group3': batch['labels4']\n#             }\n#             sup_loss = trainer.supervised_step(batch, true_labels)\n#             total_sup_loss += sup_loss\n#         # Validation loop\n#         model.eval()\n#         val_accuracies = [0, 0, 0, 0, 0]\n#         for batch in val_loader:\n#             batch = {k: v.to(device) for k, v in batch.items()}\n#             true_labels = {\n#                 'supergroup': batch['labels1'],\n#                 'group1': batch['labels2'],\n#                 'group2': batch['labels3'],\n#                 'group3': batch['labels4']\n#             }\n#             accs = trainer.validation_step(batch, true_labels)\n#             val_accuracies = [sum(x) for x in zip(val_accuracies, accs)]\n#         # Average accuracies\n#         val_accuracies = [x / len(val_loader) for x in val_accuracies]\n#         print(f\"Epoch {epoch + 1}/{num_epochs} - \"\n#               f\"Train Loss: {total_sup_loss / len(train_loader):.4f}, \"\n#               f\"Val Accuracies - Supergroup: {val_accuracies[0]:.4f}, Group1: {val_accuracies[1]:.4f}, \"\n#               f\"Group2: {val_accuracies[2]:.4f}, Group3: {val_accuracies[3]:.4f}, Item Accuracy: {val_accuracies[4]:.4f}\")\n# # Usage\n# model = AdvancedHierarchicalClassifier(num_supergroups=32, num_groups=228, num_modules=449, num_brands=5679).to(DEVICE)\n\n# # For loading the model saved after pre-training the saved dict\n# model_path = os.path.join(model_dir, \"model.pth\")\n# model.load_state_dict(torch.load(model_path))\n\n# # Assuming you have train_loader and val_loader already defined\n# train_and_evaluate(model, train_loader, val_loader, num_epochs=NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T16:41:25.821403Z","iopub.execute_input":"2024-10-21T16:41:25.821826Z"},"papermill":{"duration":15463.352693,"end_time":"2024-10-21T15:33:01.808915","exception":false,"start_time":"2024-10-21T11:15:18.456222","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"965262e96f2943f785bbaa7ea9a91998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c46252dbd774787837cdc5e1811ed23"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_30/3210967322.py:167: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/14 - Train Loss: 25.8242, Val Accuracies - Supergroup: 0.6602, Group1: 0.5898, Group2: 0.0625, Group3: 0.0000, Item Accuracy: 0.0000\nEpoch 2/14 - Train Loss: 9.0602, Val Accuracies - Supergroup: 0.9961, Group1: 0.9961, Group2: 0.9961, Group3: 0.6602, Item Accuracy: 0.6602\nEpoch 3/14 - Train Loss: 3.5734, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 4/14 - Train Loss: 1.2671, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 5/14 - Train Loss: 0.5953, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 6/14 - Train Loss: 0.3582, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 7/14 - Train Loss: 0.2457, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 8/14 - Train Loss: 0.1894, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 9/14 - Train Loss: 0.1546, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 10/14 - Train Loss: 0.1319, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 11/14 - Train Loss: 0.1155, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\nEpoch 12/14 - Train Loss: 0.1022, Val Accuracies - Supergroup: 1.0000, Group1: 1.0000, Group2: 1.0000, Group3: 1.0000, Item Accuracy: 1.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"class JointAccuracyTrainer:\n    def __init__(self, model, supervised_lr=5e-6, rl_lr=1e-4, contrastive_temperature=0.07, loss_weights=None):\n        self.model = model\n        self.device = next(model.parameters()).device\n        \n        # Split parameters into pretrained and task-specific groups\n        pretrained_params = {'params': model.model.parameters(), 'lr': supervised_lr * 0.1}\n        task_params = {'params': [p for n, p in model.named_parameters() if not n.startswith('model')], \n                      'lr': supervised_lr}\n        \n        self.supervised_optimizer = torch.optim.AdamW(\n            [pretrained_params, task_params],\n            weight_decay=0.1,\n            betas=(0.9, 0.999)\n        )\n        \n        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.supervised_optimizer,\n            T_0=5,\n            T_mult=1,\n            eta_min=supervised_lr * 0.1\n        )\n        \n        self.rl_optimizer = torch.optim.AdamW(model.parameters(), lr=rl_lr)\n        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n        self.contrastive_temperature = contrastive_temperature\n        \n        if loss_weights is None:\n            self.loss_weights = [1.2, 1.0, 1.0, 1.0]\n        else:\n            self.loss_weights = loss_weights\n            \n        self.mixup_alpha = 0.4\n        \n    def mixup_batch(self, batch):\n        \"\"\"\n        Apply mixup to the entire batch while preserving attention masks\n        \"\"\"\n        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n        batch_size = batch['input_ids'].size(0)\n        index = torch.randperm(batch_size).to(self.device)\n        \n        mixed_batch = {}\n        \n        # Handle input_ids and attention_mask\n        mixed_batch['input_ids'] = batch['input_ids']  # Keep original input_ids\n        mixed_batch['attention_mask'] = batch['attention_mask']  # Keep original attention_mask\n        \n        # Handle labels with mixup\n        label_keys = ['labels1', 'labels2', 'labels3', 'labels4']\n        for key in label_keys:\n            if key in batch:\n                mixed_batch[key] = {\n                    'labels': batch[key],\n                    'mixed_labels': batch[key][index],\n                    'lambda': lam\n                }\n        \n        return mixed_batch, lam\n        \n    def compute_mixed_loss(self, logits, label_dict):\n        \"\"\"\n        Compute loss for mixed-up labels\n        \"\"\"\n        labels = label_dict['labels']\n        mixed_labels = label_dict['mixed_labels']\n        lam = label_dict['lambda']\n        \n        loss = lam * self.criterion(logits, labels) + (1 - lam) * self.criterion(logits, mixed_labels)\n        return loss\n\n    def compute_joint_loss(self, all_outputs, mixed_labels):\n        supervised_logits, policy_logits, projection, few_shot_logits = all_outputs\n        logits_supergroup, logits_group1, logits_group2, logits_group3 = supervised_logits\n        \n        # Compute losses with mixup\n        loss_supergroup = self.compute_mixed_loss(logits_supergroup, mixed_labels['labels1'])\n        loss_group1 = self.compute_mixed_loss(logits_group1, mixed_labels['labels2'])\n        loss_group2 = self.compute_mixed_loss(logits_group2, mixed_labels['labels3'])\n        loss_group3 = self.compute_mixed_loss(logits_group3, mixed_labels['labels4'])\n        \n        # Add L2 regularization\n        l2_reg = sum(torch.norm(param, 2) for param in self.model.parameters())\n        reg_loss = 0.01 * l2_reg\n        \n        total_loss = (\n            self.loss_weights[0] * loss_supergroup + \n            self.loss_weights[1] * loss_group1 + \n            self.loss_weights[2] * loss_group2 + \n            self.loss_weights[3] * loss_group3 + \n            reg_loss\n        )\n        return total_loss\n        \n    def supervised_step(self, batch):\n        self.supervised_optimizer.zero_grad()\n        \n        # Apply mixup to the batch\n        mixed_batch, _ = self.mixup_batch(batch)\n        \n        # Forward pass\n        all_outputs = self.model(\n            mixed_batch['input_ids'],\n            mixed_batch['attention_mask']\n        )\n        \n        # Compute loss\n        total_loss = self.compute_joint_loss(all_outputs, mixed_batch)\n        \n        # Backward pass\n        total_loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n        self.supervised_optimizer.step()\n        \n        return total_loss.item()\n\n    def validation_step(self, batch):\n        \"\"\"\n        Perform a validation step without mixup\n        \"\"\"\n        with torch.no_grad():\n            outputs = self.model(batch['input_ids'], batch['attention_mask'])\n            supervised_logits = outputs[0]\n            \n            # Compute accuracies for each level\n            accuracies = []\n            for i, logits in enumerate(supervised_logits):\n                preds = torch.argmax(logits, dim=1)\n                label_key = f'labels{i+1}'\n                acc = (preds == batch[label_key]).float().mean().item()\n                accuracies.append(acc)\n                \n            # Add combined accuracy\n            combined_correct = torch.all(\n                torch.stack([preds == batch[f'labels{i+1}'] for i, preds in enumerate(supervised_logits)]),\n                dim=0\n            )\n            accuracies.append(combined_correct.float().mean().item())\n            \n            return accuracies\n\ndef train_and_evaluate(model, train_loader, val_loader, num_epochs=30):\n    trainer = JointAccuracyTrainer(model)\n    best_accuracy = 0\n    best_epoch = 0\n    accumulation_steps = 4\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_sup_loss = 0.0\n        \n        for i, batch in enumerate(train_loader):\n            batch = {k: v.to(trainer.device) for k, v in batch.items()}\n            \n            sup_loss = trainer.supervised_step(batch) / accumulation_steps\n            total_sup_loss += sup_loss * accumulation_steps\n            \n            if (i + 1) % accumulation_steps == 0:\n                trainer.supervised_optimizer.step()\n                trainer.supervised_optimizer.zero_grad()\n        \n        # Validation phase\n        model.eval()\n        val_accuracies = [0, 0, 0, 0, 0]\n        for batch in val_loader:\n            batch = {k: v.to(trainer.device) for k, v in batch.items()}\n            accs = trainer.validation_step(batch)\n            val_accuracies = [sum(x) for x in zip(val_accuracies, accs)]\n            \n        val_accuracies = [x / len(val_loader) for x in val_accuracies]\n        current_accuracy = val_accuracies[4]\n        \n        # Save best model\n        if current_accuracy > best_accuracy:\n            best_accuracy = current_accuracy\n            best_epoch = epoch\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': trainer.supervised_optimizer.state_dict(),\n                'scheduler_state_dict': trainer.scheduler.state_dict(),\n                'accuracy': current_accuracy,\n                'best_accuracy': best_accuracy\n            }, 'best_model_checkpoint.pth')\n        \n        # Update learning rate\n        trainer.scheduler.step()\n        \n        print(f\"Epoch {epoch + 1}/{num_epochs} - \"\n              f\"Train Loss: {total_sup_loss / len(train_loader):.4f}, \"\n              f\"Val Accuracies - Supergroup: {val_accuracies[0]:.4f}, \"\n              f\"Group1: {val_accuracies[1]:.4f}, Group2: {val_accuracies[2]:.4f}, \"\n              f\"Group3: {val_accuracies[3]:.4f}, Item Accuracy: {val_accuracies[4]:.4f}, \"\n              f\"LR: {trainer.supervised_optimizer.param_groups[0]['lr']:.2e}\")\n        \n    print(f\"Best accuracy: {best_accuracy:.4f} achieved at epoch {best_epoch + 1}\")\n    return best_accuracy\n\n# Usage\nmodel = AdvancedHierarchicalClassifier(num_supergroups=32, num_groups=228, \n                                     num_modules=449, num_brands=5679).to(device)\n\n# Load previous checkpoint\nmodel_path = '/kaggle/input/new-transformer-experiment-12-emb-xlm-roberta-tmp/New_model/model.pth'\nmodel.load_state_dict(torch.load(model_path))\n\n# Continue training\ntrain_and_evaluate(model, train_loader, val_loader, num_epochs=NUM_EPOCHS)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define the directory to save the model and tokenizer\n\nsave_directory = \"New_model\"\n\n# Create the directory if it doesn't exist\n\n\n\nif not os.path.exists(save_directory):\n\n    os.makedirs(save_directory)\n\n# Save the model's state dictionary\n\n\n\nmodel_save_path = os.path.join(save_directory, \"model.pth\")\n\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")\n\n# Save the tokenizer\n\n\n\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Tokenizer saved to {save_directory}\")","metadata":{"papermill":{"duration":2.147536,"end_time":"2024-10-21T15:33:03.968635","exception":false,"start_time":"2024-10-21T15:33:01.821099","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_feat = pd.read_json('/kaggle/input/indoml-phase2/final_test_data.features',lines=True)","metadata":{"papermill":{"duration":0.934958,"end_time":"2024-10-21T15:33:04.916142","exception":false,"start_time":"2024-10-21T15:33:03.981184","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_feat.head()","metadata":{"papermill":{"duration":0.029882,"end_time":"2024-10-21T15:33:04.958602","exception":false,"start_time":"2024-10-21T15:33:04.928720","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, tokenizer, text):\n\n    inputs = tokenizer(text, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\").to(device)\n\n    with torch.no_grad():\n\n        logits, _, _, _ = model(inputs['input_ids'], inputs['attention_mask'])\n\n    predictions = [torch.argmax(logit, dim=1).item() for logit in logits]\n\n    return predictions\n\n\n\n# Example prediction\n\nsample_text = \"Short product description here\"\n\npredictions = predict(model, tokenizer, sample_text)\n\nprint(f\"Supergroup: {predictions[0]}, Group: {predictions[1]}, Module: {predictions[2]}, Brand: {predictions[3]}\")","metadata":{"papermill":{"duration":0.060759,"end_time":"2024-10-21T15:33:05.032059","exception":false,"start_time":"2024-10-21T15:33:04.971300","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_tmp = df_test_feat[:5]","metadata":{"papermill":{"duration":0.018869,"end_time":"2024-10-21T15:33:05.063626","exception":false,"start_time":"2024-10-21T15:33:05.044757","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_pred_and_save(df_test_feat):\n\n    supergroups_list = []\n\n    groups_list = []\n\n    modules_list = []\n\n    brands_list = []\n\n    indoml_id_list = range(0, len(df_test_feat))\n\n    length_df = df_test_feat.shape[0]\n\n    with torch.no_grad():\n\n        for i in range(length_df):\n\n            if i % 1000 == 0:\n\n                print(f\"Processing {i} of {length_df - 1}\")\n\n            inputs = tokenizer(df_test_feat.iloc[i].description, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\").to(device)\n\n            logits, _, _, _ = model(inputs['input_ids'], inputs['attention_mask'])\n\n            predictions = [torch.argmax(logit, dim=1).item() for logit in logits]\n\n            # Append predictions to respective lists\n\n            supergroups_list.append(predictions[0])\n\n            groups_list.append(predictions[1])\n\n            modules_list.append(predictions[2])\n\n            brands_list.append(predictions[3])\n\n        try:\n\n            supergroups_names = supergroup_encoder.inverse_transform(supergroups_list)\n\n        except ValueError as e:\n\n            print(f\"Error in supergroups: {e}\")\n\n            supergroups_names = ['Unknown' if x not in supergroup_encoder.classes_ else x for x in supergroups_list]\n\n        try:\n\n            groups_names = group_encoder.inverse_transform(groups_list)\n\n        except ValueError as e:\n\n            print(f\"Error in groups: {e}\")\n\n            groups_names = ['Unknown' if x not in group_encoder.classes_ else x for x in groups_list]\n\n        try:\n\n            modules_names = module_encoder.inverse_transform(modules_list)\n\n        except ValueError as e:\n\n            print(f\"Error in modules: {e}\")\n\n            modules_names = ['Unknown' if x not in module_encoder.classes_ else x for x in modules_list]\n\n        try:\n\n            brands_names = brand_encoder.inverse_transform(brands_list)\n\n        except ValueError as e:\n\n            print(f\"Error in brands: {e}\")\n\n            brands_names = ['Unknown' if x not in brand_encoder.classes_ else x for x in brands_list]\n\n        # Create a DataFrame with predictions\n\n        predictions_df = pd.DataFrame({\n\n            'indoml_id': indoml_id_list,\n\n            'supergroup': supergroups_names,\n\n            'group': groups_names,\n\n            'module': modules_names,\n\n            'brand': brands_names\n\n        })\n\n        predictions_df.to_json('/kaggle/working/predictions.predict', orient='records', lines=True)\n\n        print(\"predictions.predict saved\")\n\nprint(make_test_pred_and_save(df_test_feat))","metadata":{"papermill":{"duration":1778.565323,"end_time":"2024-10-21T16:02:43.641490","exception":false,"start_time":"2024-10-21T15:33:05.076167","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.026263,"end_time":"2024-10-21T16:02:43.694709","exception":false,"start_time":"2024-10-21T16:02:43.668446","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.025967,"end_time":"2024-10-21T16:02:43.747303","exception":false,"start_time":"2024-10-21T16:02:43.721336","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}