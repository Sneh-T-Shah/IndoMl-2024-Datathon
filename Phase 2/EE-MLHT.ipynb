{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9642895,"sourceType":"datasetVersion","datasetId":5779523},{"sourceId":9708660,"sourceType":"datasetVersion","datasetId":5928256}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":39251.489594,"end_time":"2024-10-22T03:37:55.329250","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-21T16:43:43.839656","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"1c5a24d5a2fa492da0189c425c18399e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22e6f70c582e4ed2a495fde62d1e29ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ce97a8fda9546c8bdc8e4478dd36403","max":1115567652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aec0175f281f42efbebff60eeec21e63","value":1115567652}},"41b6850ce48b4e1f9c473357048d5a37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d48bea4f9ecc49a293cfa913598a3c4e","placeholder":"​","style":"IPY_MODEL_81102b4e31534a82bd7be3a5393df4f7","value":" 1.12G/1.12G [00:03&lt;00:00, 324MB/s]"}},"41feb7b2b3dd41209bd44d53ba26f818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf131e023b54e928895c848376ae25f","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba8568cc38c547b3baed652219195fdc","value":615}},"5c7f118ee6984cd981751d31da8d5817":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdddd0aec2794092a90d22aaa7ebf7a1","IPY_MODEL_22e6f70c582e4ed2a495fde62d1e29ba","IPY_MODEL_41b6850ce48b4e1f9c473357048d5a37"],"layout":"IPY_MODEL_883e134dc03b47648e55db0dc1259551"}},"81102b4e31534a82bd7be3a5393df4f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"883e134dc03b47648e55db0dc1259551":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ab1d35cf5cc4210a03e2a1ed7cde538":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce97a8fda9546c8bdc8e4478dd36403":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dbcb722a1764a29b31cacd1bfcde359":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aec0175f281f42efbebff60eeec21e63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0a679d839384d8d9454ff918c42957a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b69b7b87adc54962a628e2bdefeeedf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3b65c5b787d4236a5dcf0293e7afca6","placeholder":"​","style":"IPY_MODEL_b0a679d839384d8d9454ff918c42957a","value":" 615/615 [00:00&lt;00:00, 48.3kB/s]"}},"ba8568cc38c547b3baed652219195fdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc37579f889b40bea387b256bd281d31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdddd0aec2794092a90d22aaa7ebf7a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c5a24d5a2fa492da0189c425c18399e","placeholder":"​","style":"IPY_MODEL_9dbcb722a1764a29b31cacd1bfcde359","value":"model.safetensors: 100%"}},"be0e339319f2498bb2326b1315dadff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3b65c5b787d4236a5dcf0293e7afca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d48bea4f9ecc49a293cfa913598a3c4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1981b28e2546b798d34497e242ba9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8805497e0ae4112b26492c0cf2e8a15","IPY_MODEL_41feb7b2b3dd41209bd44d53ba26f818","IPY_MODEL_b69b7b87adc54962a628e2bdefeeedf2"],"layout":"IPY_MODEL_be0e339319f2498bb2326b1315dadff4"}},"f8805497e0ae4112b26492c0cf2e8a15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ab1d35cf5cc4210a03e2a1ed7cde538","placeholder":"​","style":"IPY_MODEL_bc37579f889b40bea387b256bd281d31","value":"config.json: 100%"}},"fdf131e023b54e928895c848376ae25f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Do not use the v1 of data, as it is trained on the retailer thing in v1 version of notebook</h1>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sklearn.metrics import accuracy_score\nimport time\nfrom torch.profiler import profile, record_function, ProfilerActivity\n\ndf_features = pd.read_json('/kaggle/input/indoml-phase2/train.features',lines=True)\ndf_labels = pd.read_json('/kaggle/input/indoml-phase2/train.labels',lines=True)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":11.309588,"end_time":"2024-10-21T16:43:57.861364","exception":false,"start_time":"2024-10-21T16:43:46.551776","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:11.870709Z","iopub.execute_input":"2024-10-27T09:41:11.870993Z","iopub.status.idle":"2024-10-27T09:41:23.220390Z","shell.execute_reply.started":"2024-10-27T09:41:11.870962Z","shell.execute_reply":"2024-10-27T09:41:23.219583Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nhuggingface_token = \"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\"\nlogin(token=huggingface_token)","metadata":{"papermill":{"duration":0.587427,"end_time":"2024-10-21T16:43:58.467021","exception":false,"start_time":"2024-10-21T16:43:57.879594","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:23.222077Z","iopub.execute_input":"2024-10-27T09:41:23.222390Z","iopub.status.idle":"2024-10-27T09:41:23.757545Z","shell.execute_reply.started":"2024-10-27T09:41:23.222357Z","shell.execute_reply":"2024-10-27T09:41:23.756619Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.merge(df_features,df_labels,on=\"indoml_id\")","metadata":{"papermill":{"duration":0.171722,"end_time":"2024-10-21T16:43:58.655243","exception":false,"start_time":"2024-10-21T16:43:58.483521","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:23.758892Z","iopub.execute_input":"2024-10-27T09:41:23.759670Z","iopub.status.idle":"2024-10-27T09:41:23.910533Z","shell.execute_reply.started":"2024-10-27T09:41:23.759622Z","shell.execute_reply":"2024-10-27T09:41:23.909764Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# df = df[:1000]","metadata":{"papermill":{"duration":0.023555,"end_time":"2024-10-21T16:43:58.695433","exception":false,"start_time":"2024-10-21T16:43:58.671878","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:23.912579Z","iopub.execute_input":"2024-10-27T09:41:23.912884Z","iopub.status.idle":"2024-10-27T09:41:23.916830Z","shell.execute_reply.started":"2024-10-27T09:41:23.912852Z","shell.execute_reply":"2024-10-27T09:41:23.915889Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ngroup_encoder = LabelEncoder()\nsupergroup_encoder = LabelEncoder()\nmodule_encoder = LabelEncoder()\nbrand_encoder = LabelEncoder()\n\n# Fit and transform each column\ndf['group'] = group_encoder.fit_transform(df['group'])\ndf['supergroup'] = supergroup_encoder.fit_transform(df['supergroup'])\ndf['module'] = module_encoder.fit_transform(df['module'])\ndf['brand'] = brand_encoder.fit_transform(df['brand'])","metadata":{"papermill":{"duration":0.853826,"end_time":"2024-10-21T16:43:59.565431","exception":false,"start_time":"2024-10-21T16:43:58.711605","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:23.918114Z","iopub.execute_input":"2024-10-27T09:41:23.918653Z","iopub.status.idle":"2024-10-27T09:41:24.688876Z","shell.execute_reply.started":"2024-10-27T09:41:23.918557Z","shell.execute_reply":"2024-10-27T09:41:24.687881Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, XLMRobertaModel\nfrom torch.distributions import Categorical\nimport numpy as np\nfrom typing import Dict, List, Union, Tuple\nimport os","metadata":{"papermill":{"duration":1.73321,"end_time":"2024-10-21T16:44:01.315254","exception":false,"start_time":"2024-10-21T16:43:59.582044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:24.690138Z","iopub.execute_input":"2024-10-27T09:41:24.691936Z","iopub.status.idle":"2024-10-27T09:41:26.204312Z","shell.execute_reply.started":"2024-10-27T09:41:24.691900Z","shell.execute_reply":"2024-10-27T09:41:26.203531Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# For using the new one\n# tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n\n# For loading the saved one\nmodel_dir = \"/kaggle/input/roberta-xml-expert-ensemble-architecture-tmp/New_model\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)","metadata":{"papermill":{"duration":0.825757,"end_time":"2024-10-21T16:44:02.157626","exception":false,"start_time":"2024-10-21T16:44:01.331869","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:26.205354Z","iopub.execute_input":"2024-10-27T09:41:26.205790Z","iopub.status.idle":"2024-10-27T09:41:27.003616Z","shell.execute_reply.started":"2024-10-27T09:41:26.205757Z","shell.execute_reply":"2024-10-27T09:41:27.002604Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 12 # Added +1 for the retailer\nBATCH_SIZE = 64\nLEARNING_RATE = 5e-5\nNUM_EPOCHS = 34\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice=DEVICE\nPATIENCE = 5  # Early stopping patience\nPATIENCE_LR = 3  # Reduce LR on plateau patience","metadata":{"papermill":{"duration":0.084507,"end_time":"2024-10-21T16:44:02.258847","exception":false,"start_time":"2024-10-21T16:44:02.174340","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:27.004791Z","iopub.execute_input":"2024-10-27T09:41:27.005096Z","iopub.status.idle":"2024-10-27T09:41:27.042733Z","shell.execute_reply.started":"2024-10-27T09:41:27.005064Z","shell.execute_reply":"2024-10-27T09:41:27.041750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport torch","metadata":{"papermill":{"duration":0.022581,"end_time":"2024-10-21T16:44:02.297614","exception":false,"start_time":"2024-10-21T16:44:02.275033","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:27.043899Z","iopub.execute_input":"2024-10-27T09:41:27.044248Z","iopub.status.idle":"2024-10-27T09:41:27.050525Z","shell.execute_reply.started":"2024-10-27T09:41:27.044215Z","shell.execute_reply":"2024-10-27T09:41:27.049687Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ProductDataset(Dataset):\n    def __init__(self, texts, labels1, labels2, labels3, labels4):\n        self.texts = texts\n        self.labels1 = labels1\n        self.labels2 = labels2\n        self.labels3 = labels3\n        self.labels4 = labels4\n        self.encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"pt\")\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        item = {key: val[idx].to(DEVICE) for key, val in self.encodings.items()}\n        item['labels1'] = torch.tensor(self.labels1[idx], device=DEVICE)\n        item['labels2'] = torch.tensor(self.labels2[idx], device=DEVICE)\n        item['labels3'] = torch.tensor(self.labels3[idx], device=DEVICE)\n        item['labels4'] = torch.tensor(self.labels4[idx], device=DEVICE)\n        return item\n        \ndef compute_accuracy(preds, labels):\n    # Convert each tensor in the list to numpy arrays\n    preds_np = [p.cpu().numpy() for p in preds]\n    labels_np = [l.cpu().numpy() for l in labels]\n    # Individual accuracies for each of the 4 labels\n    accuracies = [accuracy_score(labels_np[i], preds_np[i]) for i in range(4)]\n    # Overall accuracy where all 4 labels match\n    overall_accuracy = accuracy_score(\n        np.all([labels_np[i] == preds_np[i] for i in range(4)], axis=0), \n        np.ones(len(labels_np[0]))\n    )\n    # Return the 5 accuracies (4 individual, 1 overall)\n    return accuracies + [overall_accuracy]","metadata":{"papermill":{"duration":0.030167,"end_time":"2024-10-21T16:44:02.343766","exception":false,"start_time":"2024-10-21T16:44:02.313599","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:27.051908Z","iopub.execute_input":"2024-10-27T09:41:27.052622Z","iopub.status.idle":"2024-10-27T09:41:27.063706Z","shell.execute_reply.started":"2024-10-27T09:41:27.052561Z","shell.execute_reply":"2024-10-27T09:41:27.062900Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Split data\ntrain_texts, val_texts, train_labels1, val_labels1, train_labels2, val_labels2, train_labels3, val_labels3, train_labels4, val_labels4 = train_test_split(\n    df['description'], \n    df['supergroup'], \n    df['group'], \n    df['module'], \n    df['brand'], \n    test_size=0.2, \n    random_state=42\n)\ntrain_dataset = ProductDataset(\n    train_texts.tolist(), \n    train_labels1.tolist(), \n    train_labels2.tolist(), \n    train_labels3.tolist(), \n    train_labels4.tolist()\n)\nval_dataset = ProductDataset(\n    val_texts.tolist(), \n    val_labels1.tolist(), \n    val_labels2.tolist(), \n    val_labels3.tolist(), \n    val_labels4.tolist()\n)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"papermill":{"duration":21.880545,"end_time":"2024-10-21T16:44:24.240278","exception":false,"start_time":"2024-10-21T16:44:02.359733","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:27.066971Z","iopub.execute_input":"2024-10-27T09:41:27.067356Z","iopub.status.idle":"2024-10-27T09:41:46.640605Z","shell.execute_reply.started":"2024-10-27T09:41:27.067324Z","shell.execute_reply":"2024-10-27T09:41:46.639827Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class EnhancedHierarchicalClassifier(nn.Module):\n    def __init__(self, num_supergroups, num_groups, num_modules, num_brands, hidden_size=768, projection_dim=128):\n        super().__init__()\n        self.model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n        self.hidden_size = hidden_size\n        \n        # Original classifiers\n        self.supergroup_classifier = nn.Linear(hidden_size, num_supergroups)\n        self.group_classifier = nn.Linear(hidden_size + num_supergroups, num_groups)\n        self.module_classifier = nn.Linear(hidden_size + num_supergroups + num_groups, num_modules)\n        self.brand_classifier = nn.Linear(hidden_size + num_supergroups + num_groups + num_modules, num_brands)\n        \n        # Original RL Policy networks\n        self.supergroup_policy = nn.Linear(hidden_size, num_supergroups)\n        self.group_policy = nn.Linear(hidden_size + num_supergroups, num_groups)\n        self.module_policy = nn.Linear(hidden_size + num_supergroups + num_groups, num_modules)\n        self.brand_policy = nn.Linear(hidden_size + num_supergroups + num_groups + num_modules, num_brands)\n        \n        # Original contrastive learning projection\n        self.projection = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, projection_dim)\n        )\n        \n        # Original few-shot learning prototypes\n        self.prototypes = nn.Parameter(torch.randn(num_supergroups + num_groups + num_modules + num_brands, hidden_size))\n        \n        # FIXED: Multi-head attention for enhanced feature extraction\n        self.attention = nn.MultiheadAttention(hidden_size, num_heads=8)\n        \n        # Rest of the architecture remains the same\n        self.expert_classifiers = nn.ModuleDict({\n            'supergroup': self._make_expert_classifier(hidden_size, num_supergroups),\n            'group': self._make_expert_classifier(hidden_size + num_supergroups, num_groups),\n            'module': self._make_expert_classifier(hidden_size + num_supergroups + num_groups, num_modules),\n            'brand': self._make_expert_classifier(hidden_size + num_supergroups + num_groups + num_modules, num_brands)\n        })\n        \n        self.confidence_heads = nn.ModuleDict({\n            'supergroup': nn.Linear(hidden_size, 1),\n            'group': nn.Linear(hidden_size + num_supergroups, 1),\n            'module': nn.Linear(hidden_size + num_supergroups + num_groups, 1),\n            'brand': nn.Linear(hidden_size + num_supergroups + num_groups + num_modules, 1)\n        })\n        \n        self.auxiliary_projection = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, projection_dim // 2)\n        )\n\n    def _make_expert_classifier(self, input_dim, output_dim):\n        return nn.Sequential(\n            nn.Linear(input_dim, input_dim // 2),\n            nn.LayerNorm(input_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(input_dim // 2, output_dim)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_states = outputs.last_hidden_state  # Shape: [batch_size, seq_len, hidden_size]\n        \n        # FIXED: Correct attention mask handling\n        # Transpose hidden states to match attention input requirements [seq_len, batch_size, hidden_size]\n        hidden_states = hidden_states.transpose(0, 1)\n        \n        # Transform attention_mask for key_padding_mask\n        # attention_mask: [batch_size, seq_len] -> [batch_size, seq_len]\n        key_padding_mask = attention_mask.bool()\n        key_padding_mask = ~key_padding_mask  # Invert mask as per PyTorch convention\n        \n        # Apply multi-head attention with corrected dimensions\n        attended_output, _ = self.attention(\n            hidden_states,  # [seq_len, batch_size, hidden_size]\n            hidden_states,  # [seq_len, batch_size, hidden_size]\n            hidden_states,  # [seq_len, batch_size, hidden_size]\n            key_padding_mask=key_padding_mask  # [batch_size, seq_len]\n        )\n        \n        # Transform back to [batch_size, seq_len, hidden_size]\n        attended_output = attended_output.transpose(0, 1)\n        \n        # Pool the attended output\n        pooled_output = torch.mean(attended_output, dim=1)\n        \n        # Rest of the forward pass remains the same\n        supergroup_logits = self.supergroup_classifier(pooled_output)\n        group_input = torch.cat([pooled_output, torch.softmax(supergroup_logits, dim=1)], dim=1)\n        group_logits = self.group_classifier(group_input)\n        module_input = torch.cat([group_input, torch.softmax(group_logits, dim=1)], dim=1)\n        module_logits = self.module_classifier(module_input)\n        brand_input = torch.cat([module_input, torch.softmax(module_logits, dim=1)], dim=1)\n        brand_logits = self.brand_classifier(brand_input)\n        \n        supergroup_policy = self.supergroup_policy(pooled_output)\n        group_policy = self.group_policy(group_input)\n        module_policy = self.module_policy(module_input)\n        brand_policy = self.brand_policy(brand_input)\n        \n        projection = self.projection(pooled_output)\n        prototype_distances = torch.cdist(pooled_output, self.prototypes)\n        few_shot_logits = -prototype_distances\n        \n        expert_supergroup = self.expert_classifiers['supergroup'](pooled_output)\n        expert_group = self.expert_classifiers['group'](group_input)\n        expert_module = self.expert_classifiers['module'](module_input)\n        expert_brand = self.expert_classifiers['brand'](brand_input)\n        \n        confidences = {\n            'supergroup': torch.sigmoid(self.confidence_heads['supergroup'](pooled_output)),\n            'group': torch.sigmoid(self.confidence_heads['group'](group_input)),\n            'module': torch.sigmoid(self.confidence_heads['module'](module_input)),\n            'brand': torch.sigmoid(self.confidence_heads['brand'](brand_input))\n        }\n        \n        aux_projection = self.auxiliary_projection(pooled_output)\n        \n        return (\n            (supergroup_logits, group_logits, module_logits, brand_logits),\n            (supergroup_policy, group_policy, module_policy, brand_policy),\n            projection,\n            few_shot_logits,\n            (expert_supergroup, expert_group, expert_module, expert_brand),\n            confidences,\n            aux_projection\n        )","metadata":{"papermill":{"duration":37444.232661,"end_time":"2024-10-22T03:08:28.489683","exception":false,"start_time":"2024-10-21T16:44:24.257022","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:41:46.641911Z","iopub.execute_input":"2024-10-27T09:41:46.642237Z","iopub.status.idle":"2024-10-27T09:41:46.668710Z","shell.execute_reply.started":"2024-10-27T09:41:46.642205Z","shell.execute_reply":"2024-10-27T09:41:46.667701Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class EnhancedJointAccuracyTrainer:\n    def __init__(self, model, supervised_lr=1e-5, rl_lr=1e-4, contrastive_temperature=0.07, loss_weights=None):\n        self.model = model\n        self.device = next(model.parameters()).device\n        \n        # Original optimizers\n        self.supervised_optimizer = torch.optim.NAdam(model.parameters(), lr=supervised_lr)\n        self.rl_optimizer = torch.optim.NAdam(model.parameters(), lr=rl_lr)\n        \n        # Loss parameters\n        self.criterion = nn.CrossEntropyLoss()\n        self.contrastive_temperature = contrastive_temperature\n        self.loss_weights = loss_weights or [1.0, 1.0, 1.0, 1.0]\n        \n        # Knowledge distillation temperature\n        self.kd_temperature = 2.0\n        \n        # Focal loss gamma parameters\n        self.focal_gamma = 2.0\n\n    def compute_joint_loss(self, all_outputs, true_labels, batch_size):\n        supervised_logits, policy_logits, projection, few_shot_logits, expert_logits, confidences, aux_projection = all_outputs\n        \n        # Classification losses\n        base_losses = [\n            self.criterion(logits, true_labels[f'labels{i+1}'])\n            for i, logits in enumerate(supervised_logits)\n        ]\n        \n        # Weighted sum\n        original_loss = sum(w * l for w, l in zip(self.loss_weights, base_losses))\n        \n        # Expert ensemble loss with knowledge distillation\n        expert_losses = []\n        for base_logit, expert_logit, true_label in zip(supervised_logits, expert_logits, true_labels.values()):\n            # Knowledge distillation loss\n            soft_base = F.softmax(base_logit / self.kd_temperature, dim=1)\n            soft_expert = F.softmax(expert_logit / self.kd_temperature, dim=1)\n            kd_loss = F.kl_div(\n                F.log_softmax(base_logit / self.kd_temperature, dim=1),\n                soft_expert,\n                reduction='batchmean'\n            ) * (self.kd_temperature ** 2)\n            \n            # Focal loss for hard labels\n            ce_loss = F.cross_entropy(expert_logit, true_label, reduction='none')\n            pt = torch.exp(-ce_loss)\n            focal_loss = ((1 - pt) ** self.focal_gamma) * ce_loss\n            \n            expert_losses.append(kd_loss + focal_loss.mean())\n        \n        # Confidence-weighted loss\n        confidence_loss = 0\n        for logits, conf in zip(supervised_logits, confidences.values()):\n            pred_prob = F.softmax(logits, dim=1)\n            confidence_loss += F.mse_loss(conf, torch.max(pred_prob, dim=1)[0])\n        \n        # FIXED: Main contrastive loss with proper normalization\n        proj_norm = F.normalize(projection, dim=1)\n        similarity = torch.matmul(proj_norm, proj_norm.t()) / self.contrastive_temperature\n        contrastive_labels = torch.arange(batch_size).to(self.device)\n        contrastive_loss = F.cross_entropy(similarity, contrastive_labels)\n        \n        # FIXED: Auxiliary contrastive loss with proper dimension handling\n        aux_proj_norm = F.normalize(aux_projection, dim=1)\n        # Project aux_proj_norm to the same dimension as proj_norm if needed\n        if aux_proj_norm.size(1) != proj_norm.size(1):\n            projection_layer = nn.Linear(aux_proj_norm.size(1), proj_norm.size(1)).to(self.device)\n            aux_proj_norm = projection_layer(aux_proj_norm)\n            aux_proj_norm = F.normalize(aux_proj_norm, dim=1)\n        \n        aux_similarity = torch.matmul(aux_proj_norm, proj_norm.t()) / self.contrastive_temperature\n        aux_contrastive_loss = F.cross_entropy(aux_similarity, contrastive_labels)\n        \n        # Few-shot loss\n        few_shot_loss = F.cross_entropy(few_shot_logits, true_labels['labels1'])\n        \n        # Combine all losses with weights\n        total_loss = (\n            original_loss +\n            0.5 * sum(expert_losses) +\n            0.1 * confidence_loss +\n            0.1 * contrastive_loss +\n            0.05 * aux_contrastive_loss +\n            0.1 * few_shot_loss\n        )\n        \n        return total_loss\n\n    def supervised_step(self, batch, true_labels):\n        self.supervised_optimizer.zero_grad()\n        batch_size = batch['input_ids'].size(0)\n        all_outputs = self.model(batch['input_ids'], batch['attention_mask'])\n        total_loss = self.compute_joint_loss(all_outputs, true_labels, batch_size)\n        total_loss.backward()\n        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n        self.supervised_optimizer.step()\n        return total_loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:41:46.670056Z","iopub.execute_input":"2024-10-27T09:41:46.670914Z","iopub.status.idle":"2024-10-27T09:41:46.691463Z","shell.execute_reply.started":"2024-10-27T09:41:46.670866Z","shell.execute_reply":"2024-10-27T09:41:46.690563Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Usage\nmodel = EnhancedHierarchicalClassifier(num_supergroups=32, num_groups=228, num_modules=449, num_brands=5679).to(DEVICE)\n\n# For loading the model saved after pre-training the saved dict\nmodel.load_state_dict(torch.load('/kaggle/input/roberta-xml-expert-ensemble-architecture-tmp/best_model.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:41:46.692480Z","iopub.execute_input":"2024-10-27T09:41:46.692851Z","iopub.status.idle":"2024-10-27T09:42:02.709972Z","shell.execute_reply.started":"2024-10-27T09:41:46.692808Z","shell.execute_reply":"2024-10-27T09:42:02.708955Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748b0fc8fe804f348bb33235661c7574"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e55d526ed6ad46efa1fc794ba73371b7"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_30/3011562.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/input/roberta-xml-expert-ensemble-architecture-tmp/best_model.pth'))\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Profile on a single sample before starting the full training\nmodel.train()\nsample_batch = next(iter(train_loader))  # Get one sample batch\nsample_batch = {k: v.to(device) for k, v in sample_batch.items()}\ntrue_labels = {\n                f'labels{i+1}': sample_batch[f'labels{i+1}']\n                for i in range(4)\n            }\ntrainer = EnhancedJointAccuracyTrainer(model)\nwith profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_flops=True) as prof:\n    _ = trainer.supervised_step(sample_batch, true_labels)\n\nprint(prof.key_averages().table(sort_by=\"flops\",row_limit=10))\nprint(\"GFLOPs during training\") #GigaFLOPs\nprint(sum(k.flops for k in prof.key_averages())/1e9)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:47:20.394886Z","iopub.execute_input":"2024-10-27T09:47:20.395294Z","iopub.status.idle":"2024-10-27T09:47:25.704460Z","shell.execute_reply.started":"2024-10-27T09:47:20.395254Z","shell.execute_reply":"2024-10-27T09:47:25.703496Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/167650186.py:56: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  confidence_loss += F.mse_loss(conf, torch.max(pred_prob, dim=1)[0])\n","output_type":"stream"},{"name":"stdout","text":"-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total MFLOPs  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                               aten::mm         1.42%       9.134ms         5.02%      32.374ms     161.871us      46.822ms        13.35%      46.822ms     234.109us           200    277168.308  \n                                            aten::addmm         0.67%       4.330ms         1.39%       8.976ms      90.664us      24.114ms         6.88%      24.114ms     243.576us            99    134796.099  \n                                              aten::bmm         0.03%     198.132us         0.04%     274.779us      54.956us     281.758us         0.08%     281.758us      56.352us             5        70.779  \n                                              aten::mul         0.79%       5.083ms         2.01%      12.946ms      36.673us     522.687us         0.15%     522.687us       1.481us           353        15.857  \n                                              aten::add         0.14%     933.409us         0.20%       1.315ms      27.981us     375.549us         0.11%     375.549us       7.990us            47        14.755  \n                                          aten::baddbmm         0.01%      41.380us         0.01%      71.083us      71.083us      45.472us         0.01%      48.992us      48.992us             1        14.156  \n                    Optimizer.zero_grad#NAdam.zero_grad         0.03%     219.265us         0.03%     219.265us     219.265us       0.000us         0.00%       0.000us       0.000us             1            --  \n                                            aten::slice         0.04%     273.638us         0.05%     321.323us       9.181us       0.000us         0.00%       0.000us       0.000us            35            --  \n                                       aten::as_strided         0.29%       1.858ms         0.29%       1.858ms       1.599us       0.000us         0.00%       0.000us       0.000us          1162            --  \n                                           aten::expand         0.04%     271.894us         0.05%     334.843us       7.441us       0.000us         0.00%       0.000us       0.000us            45            --  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 644.858ms\nSelf CUDA time total: 350.747ms\n\nGFLOPs during training\n412.079953576\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_evaluate(model, train_loader, val_loader, num_epochs=10):\n    trainer = EnhancedJointAccuracyTrainer(model)\n    best_accuracy = 0\n    patience = 5\n    no_improve = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        \n        for batch_idx, batch in enumerate(train_loader):\n            batch = {k: v.to(trainer.device) for k, v in batch.items()}\n            true_labels = {\n                f'labels{i+1}': batch[f'labels{i+1}']\n                for i in range(4)\n            }\n            loss = trainer.supervised_step(batch, true_labels)\n            total_loss += loss\n            \n            if batch_idx % 100 == 0:\n                print(f\"Batch {batch_idx}, Loss: {loss:.4f}\")\n        \n        avg_loss = total_loss / len(train_loader)\n        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n        print(f\"Average Training Loss: {avg_loss:.4f}\")\n        \n        # Validation\n        model.eval()\n        val_accuracies = [0, 0, 0, 0, 0]\n        val_loss = 0\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(trainer.device) for k, v in batch.items()}\n                outputs = model(batch['input_ids'], batch['attention_mask'])\n                supervised_logits = outputs[0]\n                \n                true_labels = {\n                    f'labels{i+1}': batch[f'labels{i+1}']\n                    for i in range(4)\n                }\n                \n                val_loss += trainer.compute_joint_loss(outputs, true_labels, batch['input_ids'].size(0)).item()\n                \n                # Calculate accuracies\n                for i, logits in enumerate(supervised_logits):\n                    preds = torch.argmax(logits, dim=1)\n                    val_accuracies[i] += (preds == batch[f'labels{i+1}']).float().mean().item()\n                \n                # Calculate joint accuracy\n                all_correct = torch.all(torch.stack([\n                    torch.argmax(logits, dim=1) == batch[f'labels{i+1}']\n                    for i, logits in enumerate(supervised_logits)\n                ]), dim=0)\n                val_accuracies[4] += all_correct.float().mean().item()\n        \n        val_accuracies = [acc / len(val_loader) for acc in val_accuracies]\n        avg_val_loss = val_loss / len(val_loader)\n        \n        print(f\"\\nValidation Results:\")\n        print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n        print(f\"Supergroup Accuracy: {val_accuracies[0]:.4f}\")\n        print(f\"Group Accuracy: {val_accuracies[1]:.4f}\")\n        print(f\"Module Accuracy: {val_accuracies[2]:.4f}\")\n        print(f\"Brand Accuracy: {val_accuracies[3]:.4f}\")\n        print(f\"Joint Accuracy: {val_accuracies[4]:.4f}\")\n        \n        # Save best model and early stopping\n        if val_accuracies[4] > best_accuracy:\n            best_accuracy = val_accuracies[4]\n            torch.save(model.state_dict(), \"best_model.pth\")\n            print(f\"New best model saved with joint accuracy: {best_accuracy:.4f}\")\n            no_improve = 0\n        else:\n            no_improve += 1\n            if no_improve >= patience:\n                print(\"Early stopping triggered after\", patience, \"epochs without improvement\")\n                break\n\ntrain_and_evaluate(model, train_loader, val_loader, num_epochs=NUM_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:42:04.876240Z","iopub.status.idle":"2024-10-27T09:42:04.876871Z","shell.execute_reply.started":"2024-10-27T09:42:04.876528Z","shell.execute_reply":"2024-10-27T09:42:04.876555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define the directory to save the model and tokenizer\nsave_directory = \"New_model\"\n\n# Create the directory if it doesn't exist\nif not os.path.exists(save_directory):\n    os.makedirs(save_directory)\n\n# Save the model's state dictionary\nmodel_save_path = os.path.join(save_directory, \"model.pth\")\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\nprint(f\"Tokenizer saved to {save_directory}\")","metadata":{"papermill":{"duration":2.154582,"end_time":"2024-10-22T03:08:30.663580","exception":false,"start_time":"2024-10-22T03:08:28.508998","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:42:04.878735Z","iopub.status.idle":"2024-10-27T09:42:04.879109Z","shell.execute_reply.started":"2024-10-27T09:42:04.878923Z","shell.execute_reply":"2024-10-27T09:42:04.878942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_feat = pd.read_json('/kaggle/input/indoml-phase2/final_test_data.features',lines=True)","metadata":{"papermill":{"duration":0.940418,"end_time":"2024-10-22T03:08:31.623742","exception":false,"start_time":"2024-10-22T03:08:30.683324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:47:53.335551Z","iopub.execute_input":"2024-10-27T09:47:53.336493Z","iopub.status.idle":"2024-10-27T09:47:54.234248Z","shell.execute_reply.started":"2024-10-27T09:47:53.336450Z","shell.execute_reply":"2024-10-27T09:47:54.233213Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_test_feat.head()","metadata":{"papermill":{"duration":0.046924,"end_time":"2024-10-22T03:08:31.691949","exception":false,"start_time":"2024-10-22T03:08:31.645025","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:47:54.235927Z","iopub.execute_input":"2024-10-27T09:47:54.236251Z","iopub.status.idle":"2024-10-27T09:47:54.251773Z","shell.execute_reply.started":"2024-10-27T09:47:54.236210Z","shell.execute_reply":"2024-10-27T09:47:54.250866Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   indoml_id                    description retailer  price\n0          0             14 in hybrid blade    wilko   4.50\n1          1         2 pk vent stick a fres  noshify   0.69\n2          2               4 tyrefix 450 ml  noshify   2.99\n3          3           4 x 4 tyrefix 450 ml  noshify   2.99\n4          4  5 l adbluescr diesel vehicles  noshify   4.99","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>indoml_id</th>\n      <th>description</th>\n      <th>retailer</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>14 in hybrid blade</td>\n      <td>wilko</td>\n      <td>4.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2 pk vent stick a fres</td>\n      <td>noshify</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4 tyrefix 450 ml</td>\n      <td>noshify</td>\n      <td>2.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4 x 4 tyrefix 450 ml</td>\n      <td>noshify</td>\n      <td>2.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5 l adbluescr diesel vehicles</td>\n      <td>noshify</td>\n      <td>4.99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def predict(model, tokenizer, text, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n    \"\"\"\n    Make predictions using the enhanced hierarchical classifier.\n    \n    Args:\n        model: The trained EnhancedHierarchicalClassifier model\n        tokenizer: The tokenizer used for preprocessing\n        text: Input text to classify\n        device: Device to run inference on\n        \n    Returns:\n        dict: Dictionary containing predictions and confidence scores\n    \"\"\"\n    # Ensure model is in eval mode\n    model.eval()\n    \n    # Tokenize input\n    inputs = tokenizer(\n        text,\n        truncation=True,\n        padding='max_length',\n        max_length=512,  # Using standard MAX_LENGTH, adjust if needed\n        return_tensors=\"pt\"\n    ).to(device)\n    \n    # Get predictions\n    with torch.no_grad():\n        outputs = model(inputs['input_ids'], inputs['attention_mask'])\n        \n        # Unpack model outputs\n        logits, _, _, _, expert_logits, confidences, _ = outputs\n        \n        # Get predictions from main classifiers\n        predictions = [torch.argmax(logit, dim=1).item() for logit in logits]\n        \n        # Get confidence scores\n        confidence_scores = {\n            'supergroup': confidences['supergroup'].item(),\n            'group': confidences['group'].item(),\n            'module': confidences['module'].item(),\n            'brand': confidences['brand'].item()\n        }\n        \n        # Get probabilities\n        probabilities = [F.softmax(logit, dim=1).max(1).values.item() for logit in logits]\n        \n        # Get expert predictions\n        expert_predictions = [torch.argmax(logit, dim=1).item() for logit in expert_logits]\n        \n    # Combine results\n    result = {\n        'predictions': {\n            'supergroup': predictions[0],\n            'group': predictions[1],\n            'module': predictions[2],\n            'brand': predictions[3]\n        },\n        'expert_predictions': {\n            'supergroup': expert_predictions[0],\n            'group': expert_predictions[1],\n            'module': expert_predictions[2],\n            'brand': expert_predictions[3]\n        },\n        'confidence_scores': confidence_scores,\n        'probabilities': {\n            'supergroup': probabilities[0],\n            'group': probabilities[1],\n            'module': probabilities[2],\n            'brand': probabilities[3]\n        }\n    }\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:47:54.253013Z","iopub.execute_input":"2024-10-27T09:47:54.253310Z","iopub.status.idle":"2024-10-27T09:47:54.264777Z","shell.execute_reply.started":"2024-10-27T09:47:54.253278Z","shell.execute_reply":"2024-10-27T09:47:54.263876Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def reconcile_predictions(\n    model, \n    tokenizer, \n    text: str,\n    confidence_threshold: float = 0.8,\n    probability_threshold: float = 0.7,\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n) -> Tuple[int, int, int, int]:\n\n    # Get initial predictions\n    predictions = predict(model, tokenizer, text, device)\n    \n    # Initialize final predictions\n    final_predictions = []\n    \n    # Process each category\n    categories = ['supergroup', 'group', 'module', 'brand']\n    for category in categories:\n        main_pred = predictions['predictions'][category]\n        expert_pred = predictions['expert_predictions'][category]\n        confidence = predictions['confidence_scores'][category]\n        probability = predictions['probabilities'][category]\n        \n        # Decision logic\n        if main_pred == expert_pred:\n            final_pred = main_pred\n        else:\n            # Case 1: High confidence and probability in main prediction\n            if confidence >= confidence_threshold and probability >= probability_threshold:\n                final_pred = main_pred\n            \n            # Case 2: Low confidence or probability - trust expert\n            elif confidence < confidence_threshold or probability < probability_threshold:\n                final_pred = expert_pred\n            \n            # Case 3: Moderate confidence/probability - use weighted ensemble\n            else:\n                final_pred = _weighted_ensemble_decision(\n                    main_pred=main_pred,\n                    expert_pred=expert_pred,\n                    confidence=confidence,\n                    probability=probability\n                )\n        \n        final_predictions.append(final_pred)\n    \n    return tuple(final_predictions)\n\ndef _weighted_ensemble_decision(\n    main_pred: int,\n    expert_pred: int,\n    confidence: float,\n    probability: float\n) -> int:\n\n    main_weight = (confidence + probability) / 2\n    return main_pred if main_weight >= 0.5 else expert_pred","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:47:54.809601Z","iopub.execute_input":"2024-10-27T09:47:54.810524Z","iopub.status.idle":"2024-10-27T09:47:54.820812Z","shell.execute_reply.started":"2024-10-27T09:47:54.810464Z","shell.execute_reply":"2024-10-27T09:47:54.819929Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# df_test_feat = df_test_feat[:50]","metadata":{"papermill":{"duration":0.026937,"end_time":"2024-10-22T03:08:31.829731","exception":false,"start_time":"2024-10-22T03:08:31.802794","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:47:56.307552Z","iopub.execute_input":"2024-10-27T09:47:56.308205Z","iopub.status.idle":"2024-10-27T09:47:56.312535Z","shell.execute_reply.started":"2024-10-27T09:47:56.308165Z","shell.execute_reply":"2024-10-27T09:47:56.311540Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Single prediction\ntext = \"14 in hybrid blade\"\nstart = time.time()\nwith profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],with_flops=True) as prof:\n    supergroup, group, module, brand = reconcile_predictions(model, tokenizer, text)\n\nprint(\"Inference time :\"+str(time.time()-start))\n#print(prof.key_averages().table(sort_by=\"flops\",row_limit=10))\nprint(\"GFLOPs during testing\") #GigaFLOPs\nprint(sum(k.flops for k in prof.key_averages())/1e9)\nprint(supergroup, group, module, brand)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:48:04.696900Z","iopub.execute_input":"2024-10-27T09:48:04.697275Z","iopub.status.idle":"2024-10-27T09:48:05.423347Z","shell.execute_reply.started":"2024-10-27T09:48:04.697238Z","shell.execute_reply":"2024-10-27T09:48:05.422283Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Inference time :0.6268398761749268\nGFLOPs during testing\n90.267961794\n0 115 89 4078\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_test_pred_and_save(df_test_feat):\n    supergroups_list = []\n    groups_list = []\n    modules_list = []\n    brands_list = []\n    indoml_id_list = range(0, len(df_test_feat))\n    length_df = df_test_feat.shape[0]\n    with torch.no_grad():\n        for i in range(length_df):\n            if i % 1000 == 0:\n                print(f\"Processing {i} of {length_df - 1}\")\n            predictions = reconcile_predictions(model, tokenizer, df_test_feat.iloc[i].description)\n            \n            # Append predictions to respective lists\n            supergroups_list.append(predictions[0])\n            groups_list.append(predictions[1])\n            modules_list.append(predictions[2])\n            brands_list.append(predictions[3])\n\n        try:\n            supergroups_names = supergroup_encoder.inverse_transform(supergroups_list)\n        except ValueError as e:\n            print(f\"Error in supergroups: {e}\")\n            supergroups_names = ['Unknown' if x not in supergroup_encoder.classes_ else x for x in supergroups_list]\n        try:\n            groups_names = group_encoder.inverse_transform(groups_list)\n        except ValueError as e:\n            print(f\"Error in groups: {e}\")\n            groups_names = ['Unknown' if x not in group_encoder.classes_ else x for x in groups_list]\n        try:\n            modules_names = module_encoder.inverse_transform(modules_list)\n        except ValueError as e:\n            print(f\"Error in modules: {e}\")\n            modules_names = ['Unknown' if x not in module_encoder.classes_ else x for x in modules_list]\n        try:\n            brands_names = brand_encoder.inverse_transform(brands_list)\n        except ValueError as e:\n            print(f\"Error in brands: {e}\")\n            brands_names = ['Unknown' if x not in brand_encoder.classes_ else x for x in brands_list]\n        # Create a DataFrame with predictions\n        predictions_df = pd.DataFrame({\n            'indoml_id': indoml_id_list,\n            'supergroup': supergroups_names,\n            'group': groups_names,\n            'module': modules_names,\n            'brand': brands_names\n        })\n        predictions_df.to_json('/kaggle/working/predictions.predict', orient='records', lines=True)\n        print(\"predictions.predict saved\")\nmake_test_pred_and_save(df_test_feat)","metadata":{"papermill":{"duration":1760.492917,"end_time":"2024-10-22T03:37:52.342903","exception":false,"start_time":"2024-10-22T03:08:31.849986","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-27T09:42:04.890346Z","iopub.status.idle":"2024-10-27T09:42:04.890734Z","shell.execute_reply.started":"2024-10-27T09:42:04.890515Z","shell.execute_reply":"2024-10-27T09:42:04.890532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.033131,"end_time":"2024-10-22T03:37:52.409939","exception":false,"start_time":"2024-10-22T03:37:52.376808","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.033122,"end_time":"2024-10-22T03:37:52.476348","exception":false,"start_time":"2024-10-22T03:37:52.443226","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}