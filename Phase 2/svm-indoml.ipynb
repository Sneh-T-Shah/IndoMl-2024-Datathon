{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9509919,"sourceType":"datasetVersion","datasetId":5779523},{"sourceId":9529950,"sourceType":"datasetVersion","datasetId":5803595},{"sourceId":9548539,"sourceType":"datasetVersion","datasetId":5817667}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport gc\nimport cupy as cp\nfrom cuml import SVC\nfrom sklearn.metrics import classification_report\nfrom transformers import BertTokenizer, BertModel\nimport joblib\nimport json\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:07.356997Z","iopub.execute_input":"2024-10-12T12:03:07.357472Z","iopub.status.idle":"2024-10-12T12:03:20.793716Z","shell.execute_reply.started":"2024-10-12T12:03:07.357405Z","shell.execute_reply":"2024-10-12T12:03:20.792925Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_svm_model(filename):\n    \"\"\"Load the SVM model from a file.\"\"\"\n    svm = joblib.load(filename)\n    print(f\"Model loaded from {filename}\")\n    return svm\n\ndef infer_with_svm(svm, test_data):\n    \"\"\"Perform inference using the loaded SVM model.\"\"\"\n    # Convert test_data to a CuPy array if it's not already\n    if not isinstance(test_data, cp.ndarray):\n        test_data = cp.array(test_data)\n\n    # Make predictions\n    predictions = svm.predict(test_data)\n\n    return cp.asnumpy(predictions)  # Convert predictions back to NumPy array if needed\n\n# Load the model\nsvm_model = load_svm_model(\"/kaggle/input/indoml-tmp-svm/svm_model_supergroup.pkl\")  # Replace 'some_feature' with the actual feature name","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-12T12:03:20.795411Z","iopub.execute_input":"2024-10-12T12:03:20.795989Z","iopub.status.idle":"2024-10-12T12:03:21.228352Z","shell.execute_reply.started":"2024-10-12T12:03:20.795924Z","shell.execute_reply":"2024-10-12T12:03:21.227400Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/input/indoml-tmp-svm/svm_model_supergroup.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load data\ndef load_data(input_file, labels_file):\n    input_data = pd.read_json(input_file, lines=True)\n    labels_data = pd.read_json(labels_file, lines=True)\n    \n#     input_data = input_data[:100000]\n#     labels_data = labels_data[:100000]\n    \n    # Merge the input and labels data on indoml_id\n    merged_data = pd.merge(input_data, labels_data, on='indoml_id', how='inner')\n    \n    return merged_data","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:21.229855Z","iopub.execute_input":"2024-10-12T12:03:21.230306Z","iopub.status.idle":"2024-10-12T12:03:21.236079Z","shell.execute_reply.started":"2024-10-12T12:03:21.230257Z","shell.execute_reply":"2024-10-12T12:03:21.235094Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = load_data('/kaggle/input/indoml-phase2/train.features', '/kaggle/input/indoml-phase2/train.labels')","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:21.238955Z","iopub.execute_input":"2024-10-12T12:03:21.239441Z","iopub.status.idle":"2024-10-12T12:03:27.620851Z","shell.execute_reply.started":"2024-10-12T12:03:21.239396Z","shell.execute_reply":"2024-10-12T12:03:27.619861Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_test_data(input_file):\n    input_data = pd.read_json(input_file, lines=True)\n#     input_data = input_data[:1000]\n\n    return input_data\n\ntest_data = load_test_data('/kaggle/input/indoml-phase2/phase_2_test_set1.features')","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:27.622112Z","iopub.execute_input":"2024-10-12T12:03:27.622401Z","iopub.status.idle":"2024-10-12T12:03:27.986754Z","shell.execute_reply.started":"2024-10-12T12:03:27.622370Z","shell.execute_reply":"2024-10-12T12:03:27.985980Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generate_embeddings(texts, max_length=16, batch_size=32):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    model = BertModel.from_pretrained('bert-base-uncased').to(device)\n    \n    embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n        inputs = tokenizer(batch, return_tensors='pt', max_length=max_length, \n                           truncation=True, padding='max_length')\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n        embeddings.extend(batch_embeddings)\n    \n    del tokenizer\n    del model\n    gc.collect()\n    \n    return cp.array(embeddings)  # Convert to cupy array for GPU operations","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:27.988003Z","iopub.execute_input":"2024-10-12T12:03:27.988367Z","iopub.status.idle":"2024-10-12T12:03:27.997473Z","shell.execute_reply.started":"2024-10-12T12:03:27.988326Z","shell.execute_reply":"2024-10-12T12:03:27.996313Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tmp = generate_embeddings([\"1 adblue\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:27.998622Z","iopub.execute_input":"2024-10-12T12:03:27.998999Z","iopub.status.idle":"2024-10-12T12:03:32.547928Z","shell.execute_reply.started":"2024-10-12T12:03:27.998957Z","shell.execute_reply":"2024-10-12T12:03:32.546959Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d66eea9fe4d04862b72894114ec41c97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2dd5d4f8114af38337b9bc9c254b8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0deed3d0b2442d6b98317341060d5ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a53a77f1d7489fa96d0d7d89d60e33"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae65cd1fdcb41e0865b3036c65d9cca"}},"metadata":{}}]},{"cell_type":"code","source":"def encode_labels(df):\n    label_encoders = {}\n    encoded_labels = {}\n    for column in ['supergroup', 'group', 'module', 'brand']:\n        le = LabelEncoder()\n        # Check if the column contains valid data\n        if df[column].dtype == 'object':\n            df[column].replace('', np.nan, inplace=True)\n            df[column].dropna(inplace=True)\n        \n        encoded_labels[column] = cp.array(le.fit_transform(df[column].astype(str)))  # Ensure all data is string before encoding\n        label_encoders[column] = le\n    return encoded_labels, label_encoders","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:32.549201Z","iopub.execute_input":"2024-10-12T12:03:32.549834Z","iopub.status.idle":"2024-10-12T12:03:32.556906Z","shell.execute_reply.started":"2024-10-12T12:03:32.549800Z","shell.execute_reply":"2024-10-12T12:03:32.555340Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:32.558143Z","iopub.execute_input":"2024-10-12T12:03:32.558570Z","iopub.status.idle":"2024-10-12T12:03:32.666598Z","shell.execute_reply.started":"2024-10-12T12:03:32.558528Z","shell.execute_reply":"2024-10-12T12:03:32.665670Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"encoded_labels, label_encoders = encode_labels(data)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:32.670900Z","iopub.execute_input":"2024-10-12T12:03:32.671263Z","iopub.status.idle":"2024-10-12T12:03:34.318517Z","shell.execute_reply.started":"2024-10-12T12:03:32.671223Z","shell.execute_reply":"2024-10-12T12:03:34.317716Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3831588040.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[column].replace('', np.nan, inplace=True)\n/tmp/ipykernel_30/3831588040.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[column].replace('', np.nan, inplace=True)\n/tmp/ipykernel_30/3831588040.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[column].replace('', np.nan, inplace=True)\n/tmp/ipykernel_30/3831588040.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[column].replace('', np.nan, inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example test data (replace this with your actual test data)\n\n# Perform inference\npredictions = infer_with_svm(svm_model, tmp)\n\nprint(\"Predictions:\", predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:34.319655Z","iopub.execute_input":"2024-10-12T12:03:34.320054Z","iopub.status.idle":"2024-10-12T12:03:35.241956Z","shell.execute_reply.started":"2024-10-12T12:03:34.320010Z","shell.execute_reply":"2024-10-12T12:03:35.241009Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Predictions: [12]\n","output_type":"stream"}]},{"cell_type":"code","source":"tmp2 = label_encoders['supergroup'].inverse_transform(encoded_labels[\"supergroup\"].get()).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:35.243239Z","iopub.execute_input":"2024-10-12T12:03:35.243635Z","iopub.status.idle":"2024-10-12T12:03:35.278863Z","shell.execute_reply.started":"2024-10-12T12:03:35.243590Z","shell.execute_reply":"2024-10-12T12:03:35.278145Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_embeddings = generate_embeddings(test_data['description'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:03:35.279880Z","iopub.execute_input":"2024-10-12T12:03:35.280178Z","iopub.status.idle":"2024-10-12T12:04:58.565433Z","shell.execute_reply.started":"2024-10-12T12:03:35.280146Z","shell.execute_reply":"2024-10-12T12:04:58.564394Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"test_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:04:58.566793Z","iopub.execute_input":"2024-10-12T12:04:58.567122Z","iopub.status.idle":"2024-10-12T12:04:58.573430Z","shell.execute_reply.started":"2024-10-12T12:04:58.567092Z","shell.execute_reply":"2024-10-12T12:04:58.572565Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(85462, 768)"},"metadata":{}}]},{"cell_type":"code","source":"import cupy as cp\n\ndef infer_with_svm(svm, test_data):\n    \"\"\"Perform inference using the loaded SVM model.\"\"\"\n    import cupy as cp\n\n    # Ensure test_data is 2D with shape (n_samples, n_features)\n    if len(test_data.shape) != 2:\n        raise ValueError(f\"Expected test_data to be 2D, got shape {test_data.shape}\")\n\n    # Convert test_data to CuPy array if it's not already\n    if not isinstance(test_data, cp.ndarray):\n        test_data = cp.array(test_data)\n\n    # Ensure the shape is correct\n    print(f\"test_data shape before prediction: {test_data.shape}\")\n\n    # Convert to NumPy before SVM prediction\n    predictions = svm.predict(cp.asnumpy(test_data))\n\n    # Return predictions as a NumPy array or CuPy array based on preference\n    return cp.array(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:04:58.574447Z","iopub.execute_input":"2024-10-12T12:04:58.574704Z","iopub.status.idle":"2024-10-12T12:04:58.585529Z","shell.execute_reply.started":"2024-10-12T12:04:58.574675Z","shell.execute_reply":"2024-10-12T12:04:58.584725Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"predictions = infer_with_svm(svm_model, test_embeddings)\n\npredictions","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:04:58.586628Z","iopub.execute_input":"2024-10-12T12:04:58.587179Z","iopub.status.idle":"2024-10-12T12:05:03.971544Z","shell.execute_reply.started":"2024-10-12T12:04:58.587136Z","shell.execute_reply":"2024-10-12T12:05:03.970616Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"test_data shape before prediction: (85462, 768)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([12, 12, 12, ..., 12, 12, 12])"},"metadata":{}}]},{"cell_type":"code","source":"predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:05:03.972768Z","iopub.execute_input":"2024-10-12T12:05:03.973124Z","iopub.status.idle":"2024-10-12T12:05:03.979281Z","shell.execute_reply.started":"2024-10-12T12:05:03.973087Z","shell.execute_reply":"2024-10-12T12:05:03.978351Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(85462,)"},"metadata":{}}]},{"cell_type":"code","source":"unique_classes = np.unique(predictions)\nnum_unique_classes = len(unique_classes)\nprint(unique_classes, num_unique_classes)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:05:03.980664Z","iopub.execute_input":"2024-10-12T12:05:03.981227Z","iopub.status.idle":"2024-10-12T12:05:04.985597Z","shell.execute_reply.started":"2024-10-12T12:05:03.981193Z","shell.execute_reply":"2024-10-12T12:05:04.984525Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[ 5  6 10 12] 4\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:05:04.986899Z","iopub.execute_input":"2024-10-12T12:05:04.987251Z","iopub.status.idle":"2024-10-12T12:05:04.993898Z","shell.execute_reply.started":"2024-10-12T12:05:04.987215Z","shell.execute_reply":"2024-10-12T12:05:04.992892Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([12, 12, 12, ..., 12, 12, 12])"},"metadata":{}}]},{"cell_type":"code","source":"import cupy as cp\n\ndef inverse_transform_labels(encoded_labels, label_encoders, key):\n    \"\"\"Inverse transform encoded labels using the label encoder from a dictionary.\"\"\"\n    # Get the correct label encoder from the dictionary\n    label_encoder = label_encoders.get(key)\n    \n    if label_encoder is None:\n        raise ValueError(f\"No label encoder found for key: {key}\")\n    \n    # Convert CuPy array to NumPy array if encoded_labels is a CuPy array\n    if isinstance(encoded_labels, cp.ndarray):\n        encoded_labels = encoded_labels.get()  # Explicit conversion from CuPy to NumPy\n\n    # Convert the encoded labels to a list of original labels\n    return label_encoder.inverse_transform(encoded_labels).tolist()\n\n# Assuming 'key' is the appropriate key for selecting the right label encoder\n# key = 'supergroup'  # Replace with the appropriate key\n# tmp = inverse_transform_labels(predictions, label_encoders, key)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:05:04.995021Z","iopub.execute_input":"2024-10-12T12:05:04.995379Z","iopub.status.idle":"2024-10-12T12:05:05.005378Z","shell.execute_reply.started":"2024-10-12T12:05:04.995348Z","shell.execute_reply":"2024-10-12T12:05:05.004502Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef save_transformed_labels(predictions, label_encoders, key, predictions_file, output_file=\"output.json\"):\n    \"\"\"Transform predictions to original labels and save them in the specified format.\"\"\"\n    # Inverse transform predictions using the label encoder\n    transformed_labels = inverse_transform_labels(predictions, label_encoders, key)\n\n    # Load existing predictions to retain the other values\n    with open(predictions_file, 'r') as f:\n        existing_data = [json.loads(line) for line in f]  # Load each line as a JSON object\n    \n    # Create a list of dictionaries in the specified format\n    data_to_save = []\n    for idx, original_entry in enumerate(existing_data):\n        entry = {\n            \"indoml_id\": idx,\n            \"supergroup\": transformed_labels[idx],  # Use transformed label as 'supergroup'\n            \"group\": original_entry.get(\"group\", \"automotive detail unknown total\"),  # Keep original group\n            \"module\": original_entry.get(\"module\", \"automotive\"),  # Keep original module\n            \"brand\": original_entry.get(\"brand\", \"receipt all\")  # Keep original brand\n        }\n        data_to_save.append(entry)\n    \n    # Save the modified data to a JSON file\n    with open(output_file, 'w') as f:\n        for entry in data_to_save:\n            json.dump(entry, f)\n            f.write('\\n')  # Write each dictionary on a new line\n\n# Example usage\nkey = 'supergroup'  # Replace with the actual key for the label encoder\npredictions_file = \"/kaggle/input/indoml-phase-2-predictions/preidcitions.predict\"  # The path to the original predictions JSON file\nsave_transformed_labels(predictions, label_encoders, key, predictions_file, output_file=\"output.predict\")","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:05:05.006406Z","iopub.execute_input":"2024-10-12T12:05:05.006761Z","iopub.status.idle":"2024-10-12T12:05:07.322558Z","shell.execute_reply.started":"2024-10-12T12:05:05.006710Z","shell.execute_reply":"2024-10-12T12:05:07.321783Z"},"trusted":true},"execution_count":21,"outputs":[]}]}