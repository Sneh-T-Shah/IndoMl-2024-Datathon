{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb90ba9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T07:45:37.565987Z",
     "iopub.status.busy": "2024-09-07T07:45:37.565564Z",
     "iopub.status.idle": "2024-09-07T07:46:42.690323Z",
     "shell.execute_reply": "2024-09-07T07:46:42.689160Z"
    },
    "papermill": {
     "duration": 65.139939,
     "end_time": "2024-09-07T07:46:42.693189",
     "exception": false,
     "start_time": "2024-09-07T07:45:37.553250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, TrainerCallback\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Utility function to read JSONL files\n",
    "def read_jsonl(file_path, nrows=None):\n",
    "    return pd.read_json(file_path, lines=True, nrows=nrows)\n",
    "\n",
    "# Utility function to preprocess the data\n",
    "def preprocess_data(data, solution):\n",
    "    merged = pd.merge(data, solution, on='indoml_id')\n",
    "    merged['input_text'] = merged.apply(lambda row: f\"title: {row['title']} store: {row['store']} details_Manufacturer: {row['details_Manufacturer']}\", axis=1)\n",
    "    merged['target_text'] = merged.apply(lambda row: f\"details_Brand: {row['details_Brand']} L0_category: {row['L0_category']} L1_category: {row['L1_category']} L2_category: {row['L2_category']} L3_category: {row['L3_category']} L4_category: {row['L4_category']}\", axis=1)\n",
    "    return merged[['input_text', 'target_text']]\n",
    "\n",
    "# Load the data\n",
    "train_data = read_jsonl('/kaggle/input/indoml-datathon-data/attribute_train.data')\n",
    "train_solution = read_jsonl('/kaggle/input/indoml-datathon-data/attribute_train.solution')\n",
    "test_data = read_jsonl('/kaggle/input/indoml-datathon-data/attribute_test.data')\n",
    "val_data = read_jsonl('/kaggle/input/indoml-datathon-data/attribute_val.data')\n",
    "val_solution = read_jsonl('/kaggle/input/indoml-datathon-data/attribute_val.solution')\n",
    "\n",
    "# Preprocess the data\n",
    "train_processed = preprocess_data(train_data, train_solution)\n",
    "val_processed = preprocess_data(val_data, val_solution)\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_processed)\n",
    "val_dataset = Dataset.from_pandas(val_processed)\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5615d623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T07:46:42.716537Z",
     "iopub.status.busy": "2024-09-07T07:46:42.715589Z",
     "iopub.status.idle": "2024-09-07T07:46:43.899928Z",
     "shell.execute_reply": "2024-09-07T07:46:43.898558Z"
    },
    "papermill": {
     "duration": 1.198655,
     "end_time": "2024-09-07T07:46:43.902791",
     "exception": false,
     "start_time": "2024-09-07T07:46:42.704136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_tokens.json\tmodel.safetensors\t tokenizer_config.json\r\n",
      "config.json\t\tspecial_tokens_map.json\r\n",
      "generation_config.json\tspiece.model\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/tmp-generative-op1/fine_tuned_t5_1000dp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcce6ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T07:46:43.927549Z",
     "iopub.status.busy": "2024-09-07T07:46:43.926240Z",
     "iopub.status.idle": "2024-09-07T07:46:45.150854Z",
     "shell.execute_reply": "2024-09-07T07:46:45.149651Z"
    },
    "papermill": {
     "duration": 1.239594,
     "end_time": "2024-09-07T07:46:45.153476",
     "exception": false,
     "start_time": "2024-09-07T07:46:43.913882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# # Initialize the model and tokenizer\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('/kaggle/input/tmp-generative-op2/fine_tuned_t5_1000dp/')\n",
    "tokenizer = T5Tokenizer.from_pretrained('/kaggle/input/tmp-generative-op2/fine_tuned_t5_1000dp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075637d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T07:46:45.177466Z",
     "iopub.status.busy": "2024-09-07T07:46:45.176675Z",
     "iopub.status.idle": "2024-09-07T07:53:37.995009Z",
     "shell.execute_reply": "2024-09-07T07:53:37.993939Z"
    },
    "papermill": {
     "duration": 412.832624,
     "end_time": "2024-09-07T07:53:37.997202",
     "exception": false,
     "start_time": "2024-09-07T07:46:45.164578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67704b7eda60463fbf3cac4a32ef742b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/443499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a556bd89b64d08bdb271f6cfbf464c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95035 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples['input_text']\n",
    "    targets = examples['target_text']\n",
    "    model_inputs = tokenizer(inputs, max_length=128, padding='max_length', truncation=True)\n",
    "    labels = tokenizer(targets, max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14e2bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T07:53:38.022197Z",
     "iopub.status.busy": "2024-09-07T07:53:38.021259Z",
     "iopub.status.idle": "2024-09-07T13:53:09.446830Z",
     "shell.execute_reply": "2024-09-07T13:53:09.445730Z"
    },
    "papermill": {
     "duration": 21571.440456,
     "end_time": "2024-09-07T13:53:09.449065",
     "exception": false,
     "start_time": "2024-09-07T07:53:38.008609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34650' max='34650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34650/34650 5:59:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.002025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100\n",
      "loss: 0.001\n",
      "grad_norm: 0.004528792575001717\n",
      "learning_rate: 0.001994227994227994\n",
      "epoch: 0.01443001443001443\n",
      "\n",
      "\n",
      "Step: 200\n",
      "loss: 0.002\n",
      "grad_norm: 0.018010210245847702\n",
      "learning_rate: 0.0019884559884559886\n",
      "epoch: 0.02886002886002886\n",
      "\n",
      "\n",
      "Step: 300\n",
      "loss: 0.0022\n",
      "grad_norm: 0.021679753437638283\n",
      "learning_rate: 0.0019826839826839826\n",
      "epoch: 0.04329004329004329\n",
      "\n",
      "\n",
      "Step: 400\n",
      "loss: 0.0024\n",
      "grad_norm: 0.012565764598548412\n",
      "learning_rate: 0.001976911976911977\n",
      "epoch: 0.05772005772005772\n",
      "\n",
      "\n",
      "Step: 500\n",
      "loss: 0.0025\n",
      "grad_norm: 0.012734613381326199\n",
      "learning_rate: 0.001971139971139971\n",
      "epoch: 0.07215007215007214\n",
      "\n",
      "\n",
      "Step: 600\n",
      "loss: 0.0023\n",
      "grad_norm: 0.0515560619533062\n",
      "learning_rate: 0.0019653679653679657\n",
      "epoch: 0.08658008658008658\n",
      "\n",
      "\n",
      "Step: 700\n",
      "loss: 0.0024\n",
      "grad_norm: 0.037059228867292404\n",
      "learning_rate: 0.0019595959595959597\n",
      "epoch: 0.10101010101010101\n",
      "\n",
      "\n",
      "Step: 800\n",
      "loss: 0.0022\n",
      "grad_norm: 0.01481799315661192\n",
      "learning_rate: 0.0019538239538239538\n",
      "epoch: 0.11544011544011544\n",
      "\n",
      "\n",
      "Step: 900\n",
      "loss: 0.0025\n",
      "grad_norm: 0.006264907773584127\n",
      "learning_rate: 0.001948051948051948\n",
      "epoch: 0.12987012987012986\n",
      "\n",
      "\n",
      "Step: 1000\n",
      "loss: 0.0024\n",
      "grad_norm: 0.02040230482816696\n",
      "learning_rate: 0.0019422799422799423\n",
      "epoch: 0.1443001443001443\n",
      "\n",
      "\n",
      "Step: 1100\n",
      "loss: 0.0025\n",
      "grad_norm: 0.018459072336554527\n",
      "learning_rate: 0.0019365079365079366\n",
      "epoch: 0.15873015873015872\n",
      "\n",
      "\n",
      "Step: 1200\n",
      "loss: 0.0022\n",
      "grad_norm: 0.03350021690130234\n",
      "learning_rate: 0.0019307359307359306\n",
      "epoch: 0.17316017316017315\n",
      "\n",
      "\n",
      "Step: 1300\n",
      "loss: 0.0025\n",
      "grad_norm: 0.03387558087706566\n",
      "learning_rate: 0.0019249639249639251\n",
      "epoch: 0.18759018759018758\n",
      "\n",
      "\n",
      "Step: 1400\n",
      "loss: 0.0026\n",
      "grad_norm: 0.03584432974457741\n",
      "learning_rate: 0.0019191919191919192\n",
      "epoch: 0.20202020202020202\n",
      "\n",
      "\n",
      "Step: 1500\n",
      "loss: 0.003\n",
      "grad_norm: 0.0478619746863842\n",
      "learning_rate: 0.0019134199134199135\n",
      "epoch: 0.21645021645021645\n",
      "\n",
      "\n",
      "Step: 1600\n",
      "loss: 0.003\n",
      "grad_norm: 0.031789630651474\n",
      "learning_rate: 0.0019076479076479077\n",
      "epoch: 0.23088023088023088\n",
      "\n",
      "\n",
      "Step: 1700\n",
      "loss: 0.003\n",
      "grad_norm: 0.038701992481946945\n",
      "learning_rate: 0.001901875901875902\n",
      "epoch: 0.2453102453102453\n",
      "\n",
      "\n",
      "Step: 1800\n",
      "loss: 0.0025\n",
      "grad_norm: 0.028103601187467575\n",
      "learning_rate: 0.001896103896103896\n",
      "epoch: 0.2597402597402597\n",
      "\n",
      "\n",
      "Step: 1900\n",
      "loss: 0.0023\n",
      "grad_norm: 0.025706183165311813\n",
      "learning_rate: 0.0018903318903318905\n",
      "epoch: 0.2741702741702742\n",
      "\n",
      "\n",
      "Step: 2000\n",
      "loss: 0.0024\n",
      "grad_norm: 0.005970060359686613\n",
      "learning_rate: 0.0018845598845598846\n",
      "epoch: 0.2886002886002886\n",
      "\n",
      "\n",
      "Step: 2100\n",
      "loss: 0.002\n",
      "grad_norm: 0.026052774861454964\n",
      "learning_rate: 0.0018787878787878789\n",
      "epoch: 0.30303030303030304\n",
      "\n",
      "\n",
      "Step: 2200\n",
      "loss: 0.0023\n",
      "grad_norm: 0.017937621101737022\n",
      "learning_rate: 0.0018730158730158731\n",
      "epoch: 0.31746031746031744\n",
      "\n",
      "\n",
      "Step: 2300\n",
      "loss: 0.0021\n",
      "grad_norm: 0.03274362534284592\n",
      "learning_rate: 0.0018672438672438672\n",
      "epoch: 0.3318903318903319\n",
      "\n",
      "\n",
      "Step: 2400\n",
      "loss: 0.0025\n",
      "grad_norm: 0.040785327553749084\n",
      "learning_rate: 0.0018614718614718615\n",
      "epoch: 0.3463203463203463\n",
      "\n",
      "\n",
      "Step: 2500\n",
      "loss: 0.0022\n",
      "grad_norm: 0.028172887861728668\n",
      "learning_rate: 0.0018556998556998557\n",
      "epoch: 0.36075036075036077\n",
      "\n",
      "\n",
      "Step: 2600\n",
      "loss: 0.0022\n",
      "grad_norm: 0.023453040048480034\n",
      "learning_rate: 0.00184992784992785\n",
      "epoch: 0.37518037518037517\n",
      "\n",
      "\n",
      "Step: 2700\n",
      "loss: 0.0022\n",
      "grad_norm: 0.03471938148140907\n",
      "learning_rate: 0.001844155844155844\n",
      "epoch: 0.38961038961038963\n",
      "\n",
      "\n",
      "Step: 2800\n",
      "loss: 0.0024\n",
      "grad_norm: 0.018960947170853615\n",
      "learning_rate: 0.0018383838383838386\n",
      "epoch: 0.40404040404040403\n",
      "\n",
      "\n",
      "Step: 2900\n",
      "loss: 0.0024\n",
      "grad_norm: 0.028709301725029945\n",
      "learning_rate: 0.0018326118326118326\n",
      "epoch: 0.4184704184704185\n",
      "\n",
      "\n",
      "Step: 3000\n",
      "loss: 0.0025\n",
      "grad_norm: 0.029740845784544945\n",
      "learning_rate: 0.0018268398268398269\n",
      "epoch: 0.4329004329004329\n",
      "\n",
      "\n",
      "Step: 3100\n",
      "loss: 0.0025\n",
      "grad_norm: 0.03022446669638157\n",
      "learning_rate: 0.0018210678210678212\n",
      "epoch: 0.44733044733044736\n",
      "\n",
      "\n",
      "Step: 3200\n",
      "loss: 0.0023\n",
      "grad_norm: 0.0163173396140337\n",
      "learning_rate: 0.0018152958152958152\n",
      "epoch: 0.46176046176046176\n",
      "\n",
      "\n",
      "Step: 3300\n",
      "loss: 0.0022\n",
      "grad_norm: 0.025086747482419014\n",
      "learning_rate: 0.0018095238095238095\n",
      "epoch: 0.47619047619047616\n",
      "\n",
      "\n",
      "Step: 3400\n",
      "loss: 0.0023\n",
      "grad_norm: 0.016629287973046303\n",
      "learning_rate: 0.0018037518037518038\n",
      "epoch: 0.4906204906204906\n",
      "\n",
      "\n",
      "Step: 3500\n",
      "loss: 0.0024\n",
      "grad_norm: 0.03341270610690117\n",
      "learning_rate: 0.001797979797979798\n",
      "epoch: 0.5050505050505051\n",
      "\n",
      "\n",
      "Step: 3600\n",
      "loss: 0.0023\n",
      "grad_norm: 0.032594311982393265\n",
      "learning_rate: 0.001792207792207792\n",
      "epoch: 0.5194805194805194\n",
      "\n",
      "\n",
      "Step: 3700\n",
      "loss: 0.0022\n",
      "grad_norm: 0.01850935071706772\n",
      "learning_rate: 0.0017864357864357866\n",
      "epoch: 0.5339105339105339\n",
      "\n",
      "\n",
      "Step: 3800\n",
      "loss: 0.0024\n",
      "grad_norm: 0.02752889133989811\n",
      "learning_rate: 0.0017806637806637806\n",
      "epoch: 0.5483405483405484\n",
      "\n",
      "\n",
      "Step: 3900\n",
      "loss: 0.0026\n",
      "grad_norm: 0.018525218591094017\n",
      "learning_rate: 0.001774891774891775\n",
      "epoch: 0.5627705627705628\n",
      "\n",
      "\n",
      "Step: 4000\n",
      "loss: 0.0022\n",
      "grad_norm: 0.01609552465379238\n",
      "learning_rate: 0.0017691197691197692\n",
      "epoch: 0.5772005772005772\n",
      "\n",
      "\n",
      "Step: 4100\n",
      "loss: 0.0024\n",
      "grad_norm: 0.01612882688641548\n",
      "learning_rate: 0.0017633477633477634\n",
      "epoch: 0.5916305916305916\n",
      "\n",
      "\n",
      "Step: 4200\n",
      "loss: 0.0023\n",
      "grad_norm: 0.033213209360837936\n",
      "learning_rate: 0.0017575757575757577\n",
      "epoch: 0.6060606060606061\n",
      "\n",
      "\n",
      "Step: 4300\n",
      "loss: 0.0023\n",
      "grad_norm: 0.014725913293659687\n",
      "learning_rate: 0.0017518037518037518\n",
      "epoch: 0.6204906204906205\n",
      "\n",
      "\n",
      "Step: 4400\n",
      "loss: 0.0023\n",
      "grad_norm: 0.02998686581850052\n",
      "learning_rate: 0.001746031746031746\n",
      "epoch: 0.6349206349206349\n",
      "\n",
      "\n",
      "Step: 4500\n",
      "loss: 0.0025\n",
      "grad_norm: 0.031662583351135254\n",
      "learning_rate: 0.0017402597402597403\n",
      "epoch: 0.6493506493506493\n",
      "\n",
      "\n",
      "Step: 4600\n",
      "loss: 0.0022\n",
      "grad_norm: 0.05343667045235634\n",
      "learning_rate: 0.0017344877344877346\n",
      "epoch: 0.6637806637806638\n",
      "\n",
      "\n",
      "Step: 4700\n",
      "loss: 0.0022\n",
      "grad_norm: 0.04935562610626221\n",
      "learning_rate: 0.0017287157287157286\n",
      "epoch: 0.6782106782106783\n",
      "\n",
      "\n",
      "Step: 4800\n",
      "loss: 0.0024\n",
      "grad_norm: 0.02093370258808136\n",
      "learning_rate: 0.0017229437229437231\n",
      "epoch: 0.6926406926406926\n",
      "\n",
      "\n",
      "Step: 4900\n",
      "loss: 0.0023\n",
      "grad_norm: 0.02001871168613434\n",
      "learning_rate: 0.0017171717171717172\n",
      "epoch: 0.7070707070707071\n",
      "\n",
      "\n",
      "Step: 5000\n",
      "loss: 0.002\n",
      "grad_norm: 0.017337683588266373\n",
      "learning_rate: 0.0017113997113997114\n",
      "epoch: 0.7215007215007215\n",
      "\n",
      "\n",
      "Step: 5100\n",
      "loss: 0.0021\n",
      "grad_norm: 0.023929109796881676\n",
      "learning_rate: 0.0017056277056277057\n",
      "epoch: 0.7359307359307359\n",
      "\n",
      "\n",
      "Step: 5200\n",
      "loss: 0.0021\n",
      "grad_norm: 0.018272677436470985\n",
      "learning_rate: 0.0016998556998557\n",
      "epoch: 0.7503607503607503\n",
      "\n",
      "\n",
      "Step: 5300\n",
      "loss: 0.0021\n",
      "grad_norm: 0.017609979957342148\n",
      "learning_rate: 0.001694083694083694\n",
      "epoch: 0.7647907647907648\n",
      "\n",
      "\n",
      "Step: 5400\n",
      "loss: 0.0022\n",
      "grad_norm: 0.037232037633657455\n",
      "learning_rate: 0.0016883116883116883\n",
      "epoch: 0.7792207792207793\n",
      "\n",
      "\n",
      "Step: 5500\n",
      "loss: 0.0023\n",
      "grad_norm: 0.021138755604624748\n",
      "learning_rate: 0.0016825396825396826\n",
      "epoch: 0.7936507936507936\n",
      "\n",
      "\n",
      "Step: 5600\n",
      "loss: 0.0023\n",
      "grad_norm: 0.035199686884880066\n",
      "learning_rate: 0.0016767676767676766\n",
      "epoch: 0.8080808080808081\n",
      "\n",
      "\n",
      "Step: 5700\n",
      "loss: 0.0022\n",
      "grad_norm: 0.03563110902905464\n",
      "learning_rate: 0.0016709956709956711\n",
      "epoch: 0.8225108225108225\n",
      "\n",
      "\n",
      "Step: 5800\n",
      "loss: 0.0022\n",
      "grad_norm: 0.0190757904201746\n",
      "learning_rate: 0.0016652236652236652\n",
      "epoch: 0.836940836940837\n",
      "\n",
      "\n",
      "Step: 5900\n",
      "loss: 0.0021\n",
      "grad_norm: 0.01854684390127659\n",
      "learning_rate: 0.0016594516594516595\n",
      "epoch: 0.8513708513708513\n",
      "\n",
      "\n",
      "Step: 6000\n",
      "loss: 0.0022\n",
      "grad_norm: 0.02102009952068329\n",
      "learning_rate: 0.0016536796536796537\n",
      "epoch: 0.8658008658008658\n",
      "\n",
      "\n",
      "Step: 6100\n",
      "loss: 0.0023\n",
      "grad_norm: 0.019028974696993828\n",
      "learning_rate: 0.001647907647907648\n",
      "epoch: 0.8802308802308803\n",
      "\n",
      "\n",
      "Step: 6200\n",
      "loss: 0.0022\n",
      "grad_norm: 0.018483158200979233\n",
      "learning_rate: 0.001642135642135642\n",
      "epoch: 0.8946608946608947\n",
      "\n",
      "\n",
      "Step: 6300\n",
      "loss: 0.0023\n",
      "grad_norm: 0.024363020434975624\n",
      "learning_rate: 0.0016363636363636365\n",
      "epoch: 0.9090909090909091\n",
      "\n",
      "\n",
      "Step: 6400\n",
      "loss: 0.0022\n",
      "grad_norm: 0.02164975181221962\n",
      "learning_rate: 0.0016305916305916306\n",
      "epoch: 0.9235209235209235\n",
      "\n",
      "\n",
      "Step: 6500\n",
      "loss: 0.0021\n",
      "grad_norm: 0.07298121601343155\n",
      "learning_rate: 0.0016248196248196246\n",
      "epoch: 0.937950937950938\n",
      "\n",
      "\n",
      "Step: 6600\n",
      "loss: 0.0025\n",
      "grad_norm: 0.057708173990249634\n",
      "learning_rate: 0.0016190476190476191\n",
      "epoch: 0.9523809523809523\n",
      "\n",
      "\n",
      "Step: 6700\n",
      "loss: 0.0021\n",
      "grad_norm: 0.01625773496925831\n",
      "learning_rate: 0.0016132756132756132\n",
      "epoch: 0.9668109668109668\n",
      "\n",
      "\n",
      "Step: 6800\n",
      "loss: 0.0023\n",
      "grad_norm: 0.020716484636068344\n",
      "learning_rate: 0.0016075036075036077\n",
      "epoch: 0.9812409812409812\n",
      "\n",
      "\n",
      "Step: 6900\n",
      "loss: 0.0026\n",
      "grad_norm: 0.04046418517827988\n",
      "learning_rate: 0.0016017316017316017\n",
      "epoch: 0.9956709956709957\n",
      "\n",
      "\n",
      "Step: 6930\n",
      "eval_loss: 0.0025996402837336063\n",
      "eval_runtime: 298.4164\n",
      "eval_samples_per_second: 318.464\n",
      "eval_steps_per_second: 4.976\n",
      "epoch: 1.0\n",
      "\n",
      "\n",
      "Step: 7000\n",
      "loss: 0.0021\n",
      "grad_norm: 0.027828479185700417\n",
      "learning_rate: 0.001595959595959596\n",
      "epoch: 1.0101010101010102\n",
      "\n",
      "\n",
      "Step: 7100\n",
      "loss: 0.002\n",
      "grad_norm: 0.027943043038249016\n",
      "learning_rate: 0.0015901875901875903\n",
      "epoch: 1.0245310245310246\n",
      "\n",
      "\n",
      "Step: 7200\n",
      "loss: 0.002\n",
      "grad_norm: 0.01698000356554985\n",
      "learning_rate: 0.0015844155844155845\n",
      "epoch: 1.0389610389610389\n",
      "\n",
      "\n",
      "Step: 7300\n",
      "loss: 0.0018\n",
      "grad_norm: 0.030187221243977547\n",
      "learning_rate: 0.0015786435786435786\n",
      "epoch: 1.0533910533910533\n",
      "\n",
      "\n",
      "Step: 7400\n",
      "loss: 0.002\n",
      "grad_norm: 0.021059557795524597\n",
      "learning_rate: 0.001572871572871573\n",
      "epoch: 1.0678210678210678\n",
      "\n",
      "\n",
      "Step: 7500\n",
      "loss: 0.002\n",
      "grad_norm: 0.039850421249866486\n",
      "learning_rate: 0.0015670995670995671\n",
      "epoch: 1.0822510822510822\n",
      "\n",
      "\n",
      "Step: 7600\n",
      "loss: 0.0019\n",
      "grad_norm: 0.031274620443582535\n",
      "learning_rate: 0.0015613275613275612\n",
      "epoch: 1.0966810966810967\n",
      "\n",
      "\n",
      "Step: 7700\n",
      "loss: 0.0018\n",
      "grad_norm: 0.02926125004887581\n",
      "learning_rate: 0.0015555555555555557\n",
      "epoch: 1.1111111111111112\n",
      "\n",
      "\n",
      "Step: 7800\n",
      "loss: 0.0017\n",
      "grad_norm: 0.012342456728219986\n",
      "learning_rate: 0.0015497835497835497\n",
      "epoch: 1.1255411255411256\n",
      "\n",
      "\n",
      "Step: 7900\n",
      "loss: 0.002\n",
      "grad_norm: 0.02606189250946045\n",
      "learning_rate: 0.001544011544011544\n",
      "epoch: 1.13997113997114\n",
      "\n",
      "\n",
      "Step: 8000\n",
      "loss: 0.002\n",
      "grad_norm: 0.01982792839407921\n",
      "learning_rate: 0.0015382395382395383\n",
      "epoch: 1.1544011544011543\n",
      "\n",
      "\n",
      "Step: 8100\n",
      "loss: 0.0021\n",
      "grad_norm: 0.02375229261815548\n",
      "learning_rate: 0.0015324675324675326\n",
      "epoch: 1.1688311688311688\n",
      "\n",
      "\n",
      "Step: 8200\n",
      "loss: 0.0022\n",
      "grad_norm: 0.03267791494727135\n",
      "learning_rate: 0.0015266955266955266\n",
      "epoch: 1.1832611832611832\n",
      "\n",
      "\n",
      "Step: 8300\n",
      "loss: 0.0021\n",
      "grad_norm: 0.03397644683718681\n",
      "learning_rate: 0.001520923520923521\n",
      "epoch: 1.1976911976911977\n",
      "\n",
      "\n",
      "Step: 8400\n",
      "loss: 0.0019\n",
      "grad_norm: 0.033044666051864624\n",
      "learning_rate: 0.0015151515151515152\n",
      "epoch: 1.2121212121212122\n",
      "\n",
      "\n",
      "Step: 8500\n",
      "loss: 0.0022\n",
      "grad_norm: 0.028324531391263008\n",
      "learning_rate: 0.0015093795093795094\n",
      "epoch: 1.2265512265512266\n",
      "\n",
      "\n",
      "Step: 8600\n",
      "loss: 0.002\n",
      "grad_norm: 0.017472311854362488\n",
      "learning_rate: 0.0015036075036075037\n",
      "epoch: 1.240981240981241\n",
      "\n",
      "\n",
      "Step: 8700\n",
      "loss: 0.0019\n",
      "grad_norm: 0.015902189537882805\n",
      "learning_rate: 0.0014978354978354977\n",
      "epoch: 1.2554112554112553\n",
      "\n",
      "\n",
      "Step: 8800\n",
      "loss: 0.0021\n",
      "grad_norm: 0.01129245851188898\n",
      "learning_rate: 0.001492063492063492\n",
      "epoch: 1.2698412698412698\n",
      "\n",
      "\n",
      "Step: 8900\n",
      "loss: 0.0018\n",
      "grad_norm: 0.028643885627388954\n",
      "learning_rate: 0.0014862914862914863\n",
      "epoch: 1.2842712842712842\n",
      "\n",
      "\n",
      "Step: 9000\n",
      "loss: 0.0022\n",
      "grad_norm: 0.02648053504526615\n",
      "learning_rate: 0.0014805194805194806\n",
      "epoch: 1.2987012987012987\n",
      "\n",
      "\n",
      "Step: 9100\n",
      "loss: 0.002\n",
      "grad_norm: 0.016672687605023384\n",
      "learning_rate: 0.0014747474747474748\n",
      "epoch: 1.3131313131313131\n",
      "\n",
      "\n",
      "Step: 9200\n",
      "loss: 0.0018\n",
      "grad_norm: 0.0134024852886796\n",
      "learning_rate: 0.001468975468975469\n",
      "epoch: 1.3275613275613276\n",
      "\n",
      "\n",
      "Step: 9300\n",
      "loss: 0.0019\n",
      "grad_norm: 0.027711546048521996\n",
      "learning_rate: 0.0014632034632034632\n",
      "epoch: 1.341991341991342\n",
      "\n",
      "\n",
      "Step: 9400\n",
      "loss: 0.0019\n",
      "grad_norm: 0.013814586214721203\n",
      "learning_rate: 0.0014574314574314576\n",
      "epoch: 1.3564213564213565\n",
      "\n",
      "\n",
      "Step: 9500\n",
      "loss: 0.0019\n",
      "grad_norm: 0.028208717703819275\n",
      "learning_rate: 0.0014516594516594517\n",
      "epoch: 1.370851370851371\n",
      "\n",
      "\n",
      "Step: 9600\n",
      "loss: 0.0018\n",
      "grad_norm: 0.034107357263565063\n",
      "learning_rate: 0.0014458874458874458\n",
      "epoch: 1.3852813852813852\n",
      "\n",
      "\n",
      "Step: 9700\n",
      "loss: 0.0019\n",
      "grad_norm: 0.02468700520694256\n",
      "learning_rate: 0.0014401154401154402\n",
      "epoch: 1.3997113997113997\n",
      "\n",
      "\n",
      "Step: 9800\n",
      "loss: 0.0019\n",
      "grad_norm: 0.024340465664863586\n",
      "learning_rate: 0.0014343434343434343\n",
      "epoch: 1.4141414141414141\n",
      "\n",
      "\n",
      "Step: 9900\n",
      "loss: 0.0019\n",
      "grad_norm: 0.028378073126077652\n",
      "learning_rate: 0.0014285714285714286\n",
      "epoch: 1.4285714285714286\n",
      "\n",
      "\n",
      "Step: 10000\n",
      "loss: 0.0019\n",
      "grad_norm: 0.02154083549976349\n",
      "learning_rate: 0.0014227994227994228\n",
      "epoch: 1.443001443001443\n",
      "\n",
      "\n",
      "Step: 10100\n",
      "loss: 0.0017\n",
      "grad_norm: 0.024936676025390625\n",
      "learning_rate: 0.0014170274170274171\n",
      "epoch: 1.4574314574314573\n",
      "\n",
      "\n",
      "Step: 10200\n",
      "loss: 0.002\n",
      "grad_norm: 0.009408794343471527\n",
      "learning_rate: 0.0014112554112554112\n",
      "epoch: 1.4718614718614718\n",
      "\n",
      "\n",
      "Step: 10300\n",
      "loss: 0.0019\n",
      "grad_norm: 0.019284764304757118\n",
      "learning_rate: 0.0014054834054834057\n",
      "epoch: 1.4862914862914862\n",
      "\n",
      "\n",
      "Step: 10400\n",
      "loss: 0.0018\n",
      "grad_norm: 0.022189438343048096\n",
      "learning_rate: 0.0013997113997113997\n",
      "epoch: 1.5007215007215007\n",
      "\n",
      "\n",
      "Step: 10500\n",
      "loss: 0.0018\n",
      "grad_norm: 0.02676442079246044\n",
      "learning_rate: 0.001393939393939394\n",
      "epoch: 1.5151515151515151\n",
      "\n",
      "\n",
      "Step: 10600\n",
      "loss: 0.0018\n",
      "grad_norm: 0.029680529609322548\n",
      "learning_rate: 0.0013881673881673883\n",
      "epoch: 1.5295815295815296\n",
      "\n",
      "\n",
      "Step: 10700\n",
      "loss: 0.0017\n",
      "grad_norm: 0.018222933635115623\n",
      "learning_rate: 0.0013823953823953823\n",
      "epoch: 1.544011544011544\n",
      "\n",
      "\n",
      "Step: 10800\n",
      "loss: 0.0017\n",
      "grad_norm: 0.025473270565271378\n",
      "learning_rate: 0.0013766233766233766\n",
      "epoch: 1.5584415584415585\n",
      "\n",
      "\n",
      "Step: 10900\n",
      "loss: 0.0018\n",
      "grad_norm: 0.01465350016951561\n",
      "learning_rate: 0.0013708513708513709\n",
      "epoch: 1.572871572871573\n",
      "\n",
      "\n",
      "Step: 11000\n",
      "loss: 0.0018\n",
      "grad_norm: 0.014236883260309696\n",
      "learning_rate: 0.0013650793650793651\n",
      "epoch: 1.5873015873015874\n",
      "\n",
      "\n",
      "Step: 11100\n",
      "loss: 0.0018\n",
      "grad_norm: 0.033853333443403244\n",
      "learning_rate: 0.0013593073593073592\n",
      "epoch: 1.601731601731602\n",
      "\n",
      "\n",
      "Step: 11200\n",
      "loss: 0.0017\n",
      "grad_norm: 0.031044788658618927\n",
      "learning_rate: 0.0013535353535353537\n",
      "epoch: 1.6161616161616161\n",
      "\n",
      "\n",
      "Step: 11300\n",
      "loss: 0.0018\n",
      "grad_norm: 0.015600902959704399\n",
      "learning_rate: 0.0013477633477633477\n",
      "epoch: 1.6305916305916306\n",
      "\n",
      "\n",
      "Step: 11400\n",
      "loss: 0.0017\n",
      "grad_norm: 0.01907600648701191\n",
      "learning_rate: 0.001341991341991342\n",
      "epoch: 1.645021645021645\n",
      "\n",
      "\n",
      "Step: 11500\n",
      "loss: 0.0018\n",
      "grad_norm: 0.021240882575511932\n",
      "learning_rate: 0.0013362193362193363\n",
      "epoch: 1.6594516594516593\n",
      "\n",
      "\n",
      "Step: 11600\n",
      "loss: 0.0017\n",
      "grad_norm: 0.016113488003611565\n",
      "learning_rate: 0.0013304473304473305\n",
      "epoch: 1.6738816738816737\n",
      "\n",
      "\n",
      "Step: 11700\n",
      "loss: 0.0019\n",
      "grad_norm: 0.013896876946091652\n",
      "learning_rate: 0.0013246753246753248\n",
      "epoch: 1.6883116883116882\n",
      "\n",
      "\n",
      "Step: 11800\n",
      "loss: 0.0018\n",
      "grad_norm: 0.007191587705165148\n",
      "learning_rate: 0.0013189033189033189\n",
      "epoch: 1.7027417027417027\n",
      "\n",
      "\n",
      "Step: 11900\n",
      "loss: 0.0015\n",
      "grad_norm: 0.011585093103349209\n",
      "learning_rate: 0.0013131313131313131\n",
      "epoch: 1.7171717171717171\n",
      "\n",
      "\n",
      "Step: 12000\n",
      "loss: 0.0021\n",
      "grad_norm: 0.03836695849895477\n",
      "learning_rate: 0.0013073593073593074\n",
      "epoch: 1.7316017316017316\n",
      "\n",
      "\n",
      "Step: 12100\n",
      "loss: 0.002\n",
      "grad_norm: 0.016147414222359657\n",
      "learning_rate: 0.0013015873015873017\n",
      "epoch: 1.746031746031746\n",
      "\n",
      "\n",
      "Step: 12200\n",
      "loss: 0.0018\n",
      "grad_norm: 0.011172379367053509\n",
      "learning_rate: 0.0012958152958152957\n",
      "epoch: 1.7604617604617605\n",
      "\n",
      "\n",
      "Step: 12300\n",
      "loss: 0.0017\n",
      "grad_norm: 0.025154706090688705\n",
      "learning_rate: 0.0012900432900432902\n",
      "epoch: 1.774891774891775\n",
      "\n",
      "\n",
      "Step: 12400\n",
      "loss: 0.0017\n",
      "grad_norm: 0.017441704869270325\n",
      "learning_rate: 0.0012842712842712843\n",
      "epoch: 1.7893217893217894\n",
      "\n",
      "\n",
      "Step: 12500\n",
      "loss: 0.0019\n",
      "grad_norm: 0.013023828156292439\n",
      "learning_rate: 0.0012784992784992785\n",
      "epoch: 1.8037518037518039\n",
      "\n",
      "\n",
      "Step: 12600\n",
      "loss: 0.0017\n",
      "grad_norm: 0.011731968261301517\n",
      "learning_rate: 0.0012727272727272728\n",
      "epoch: 1.8181818181818183\n",
      "\n",
      "\n",
      "Step: 12700\n",
      "loss: 0.0017\n",
      "grad_norm: 0.024893976747989655\n",
      "learning_rate: 0.001266955266955267\n",
      "epoch: 1.8326118326118326\n",
      "\n",
      "\n",
      "Step: 12800\n",
      "loss: 0.0016\n",
      "grad_norm: 0.019687380641698837\n",
      "learning_rate: 0.0012611832611832611\n",
      "epoch: 1.847041847041847\n",
      "\n",
      "\n",
      "Step: 12900\n",
      "loss: 0.0016\n",
      "grad_norm: 0.025792095810174942\n",
      "learning_rate: 0.0012554112554112554\n",
      "epoch: 1.8614718614718615\n",
      "\n",
      "\n",
      "Step: 13000\n",
      "loss: 0.0018\n",
      "grad_norm: 0.016913803294301033\n",
      "learning_rate: 0.0012496392496392497\n",
      "epoch: 1.8759018759018757\n",
      "\n",
      "\n",
      "Step: 13100\n",
      "loss: 0.0016\n",
      "grad_norm: 0.01739661954343319\n",
      "learning_rate: 0.0012438672438672437\n",
      "epoch: 1.8903318903318902\n",
      "\n",
      "\n",
      "Step: 13200\n",
      "loss: 0.0016\n",
      "grad_norm: 0.010874820873141289\n",
      "learning_rate: 0.0012380952380952382\n",
      "epoch: 1.9047619047619047\n",
      "\n",
      "\n",
      "Step: 13300\n",
      "loss: 0.0017\n",
      "grad_norm: 0.011958910152316093\n",
      "learning_rate: 0.0012323232323232323\n",
      "epoch: 1.9191919191919191\n",
      "\n",
      "\n",
      "Step: 13400\n",
      "loss: 0.0016\n",
      "grad_norm: 0.026117414236068726\n",
      "learning_rate: 0.0012265512265512266\n",
      "epoch: 1.9336219336219336\n",
      "\n",
      "\n",
      "Step: 13500\n",
      "loss: 0.0015\n",
      "grad_norm: 0.009645196609199047\n",
      "learning_rate: 0.0012207792207792208\n",
      "epoch: 1.948051948051948\n",
      "\n",
      "\n",
      "Step: 13600\n",
      "loss: 0.0016\n",
      "grad_norm: 0.020680315792560577\n",
      "learning_rate: 0.001215007215007215\n",
      "epoch: 1.9624819624819625\n",
      "\n",
      "\n",
      "Step: 13700\n",
      "loss: 0.0017\n",
      "grad_norm: 0.009475002065300941\n",
      "learning_rate: 0.0012092352092352091\n",
      "epoch: 1.976911976911977\n",
      "\n",
      "\n",
      "Step: 13800\n",
      "loss: 0.0017\n",
      "grad_norm: 0.02284531481564045\n",
      "learning_rate: 0.0012034632034632036\n",
      "epoch: 1.9913419913419914\n",
      "\n",
      "\n",
      "Step: 13860\n",
      "eval_loss: 0.002433921443298459\n",
      "eval_runtime: 295.0226\n",
      "eval_samples_per_second: 322.128\n",
      "eval_steps_per_second: 5.034\n",
      "epoch: 2.0\n",
      "\n",
      "\n",
      "Step: 13900\n",
      "loss: 0.0019\n",
      "grad_norm: 0.013980047777295113\n",
      "learning_rate: 0.0011976911976911977\n",
      "epoch: 2.005772005772006\n",
      "\n",
      "\n",
      "Step: 14000\n",
      "loss: 0.0016\n",
      "grad_norm: 0.018765578046441078\n",
      "learning_rate: 0.0011919191919191917\n",
      "epoch: 2.0202020202020203\n",
      "\n",
      "\n",
      "Step: 14100\n",
      "loss: 0.0016\n",
      "grad_norm: 0.03245999291539192\n",
      "learning_rate: 0.0011861471861471862\n",
      "epoch: 2.034632034632035\n",
      "\n",
      "\n",
      "Step: 14200\n",
      "loss: 0.0015\n",
      "grad_norm: 0.01560287270694971\n",
      "learning_rate: 0.0011803751803751803\n",
      "epoch: 2.0490620490620493\n",
      "\n",
      "\n",
      "Step: 14300\n",
      "loss: 0.0015\n",
      "grad_norm: 0.02541516162455082\n",
      "learning_rate: 0.0011746031746031748\n",
      "epoch: 2.0634920634920633\n",
      "\n",
      "\n",
      "Step: 14400\n",
      "loss: 0.0015\n",
      "grad_norm: 0.011756058782339096\n",
      "learning_rate: 0.0011688311688311688\n",
      "epoch: 2.0779220779220777\n",
      "\n",
      "\n",
      "Step: 14500\n",
      "loss: 0.0014\n",
      "grad_norm: 0.027963949367403984\n",
      "learning_rate: 0.001163059163059163\n",
      "epoch: 2.092352092352092\n",
      "\n",
      "\n",
      "Step: 14600\n",
      "loss: 0.0014\n",
      "grad_norm: 0.02363549917936325\n",
      "learning_rate: 0.0011572871572871574\n",
      "epoch: 2.1067821067821066\n",
      "\n",
      "\n",
      "Step: 14700\n",
      "loss: 0.0014\n",
      "grad_norm: 0.011819357983767986\n",
      "learning_rate: 0.0011515151515151516\n",
      "epoch: 2.121212121212121\n",
      "\n",
      "\n",
      "Step: 14800\n",
      "loss: 0.0015\n",
      "grad_norm: 0.01162776630371809\n",
      "learning_rate: 0.0011457431457431457\n",
      "epoch: 2.1356421356421356\n",
      "\n",
      "\n",
      "Step: 14900\n",
      "loss: 0.0015\n",
      "grad_norm: 0.014733943156898022\n",
      "learning_rate: 0.0011399711399711402\n",
      "epoch: 2.15007215007215\n",
      "\n",
      "\n",
      "Step: 15000\n",
      "loss: 0.0014\n",
      "grad_norm: 0.044415779411792755\n",
      "learning_rate: 0.0011341991341991342\n",
      "epoch: 2.1645021645021645\n",
      "\n",
      "\n",
      "Step: 15100\n",
      "loss: 0.0016\n",
      "grad_norm: 0.010598275810480118\n",
      "learning_rate: 0.0011284271284271283\n",
      "epoch: 2.178932178932179\n",
      "\n",
      "\n",
      "Step: 15200\n",
      "loss: 0.0015\n",
      "grad_norm: 0.021532246842980385\n",
      "learning_rate: 0.0011226551226551228\n",
      "epoch: 2.1933621933621934\n",
      "\n",
      "\n",
      "Step: 15300\n",
      "loss: 0.0014\n",
      "grad_norm: 0.01514953002333641\n",
      "learning_rate: 0.0011168831168831168\n",
      "epoch: 2.207792207792208\n",
      "\n",
      "\n",
      "Step: 15400\n",
      "loss: 0.0015\n",
      "grad_norm: 0.024042660370469093\n",
      "learning_rate: 0.0011111111111111111\n",
      "epoch: 2.2222222222222223\n",
      "\n",
      "\n",
      "Step: 15500\n",
      "loss: 0.0015\n",
      "grad_norm: 0.017748933285474777\n",
      "learning_rate: 0.0011053391053391054\n",
      "epoch: 2.236652236652237\n",
      "\n",
      "\n",
      "Step: 15600\n",
      "loss: 0.0014\n",
      "grad_norm: 0.012023947201669216\n",
      "learning_rate: 0.0010995670995670997\n",
      "epoch: 2.2510822510822512\n",
      "\n",
      "\n",
      "Step: 15700\n",
      "loss: 0.0014\n",
      "grad_norm: 0.014944886788725853\n",
      "learning_rate: 0.0010937950937950937\n",
      "epoch: 2.2655122655122657\n",
      "\n",
      "\n",
      "Step: 15800\n",
      "loss: 0.0015\n",
      "grad_norm: 0.013405428268015385\n",
      "learning_rate: 0.0010880230880230882\n",
      "epoch: 2.27994227994228\n",
      "\n",
      "\n",
      "Step: 15900\n",
      "loss: 0.0013\n",
      "grad_norm: 0.012063074856996536\n",
      "learning_rate: 0.0010822510822510823\n",
      "epoch: 2.2943722943722946\n",
      "\n",
      "\n",
      "Step: 16000\n",
      "loss: 0.0013\n",
      "grad_norm: 0.009668517857789993\n",
      "learning_rate: 0.0010764790764790763\n",
      "epoch: 2.3088023088023086\n",
      "\n",
      "\n",
      "Step: 16100\n",
      "loss: 0.0013\n",
      "grad_norm: 0.016116801649332047\n",
      "learning_rate: 0.0010707070707070708\n",
      "epoch: 2.323232323232323\n",
      "\n",
      "\n",
      "Step: 16200\n",
      "loss: 0.0014\n",
      "grad_norm: 0.011648286134004593\n",
      "learning_rate: 0.0010649350649350648\n",
      "epoch: 2.3376623376623376\n",
      "\n",
      "\n",
      "Step: 16300\n",
      "loss: 0.0013\n",
      "grad_norm: 0.02601374313235283\n",
      "learning_rate: 0.0010591630591630591\n",
      "epoch: 2.352092352092352\n",
      "\n",
      "\n",
      "Step: 16400\n",
      "loss: 0.0014\n",
      "grad_norm: 0.012073147110641003\n",
      "learning_rate: 0.0010533910533910534\n",
      "epoch: 2.3665223665223665\n",
      "\n",
      "\n",
      "Step: 16500\n",
      "loss: 0.0014\n",
      "grad_norm: 0.009620989672839642\n",
      "learning_rate: 0.0010476190476190477\n",
      "epoch: 2.380952380952381\n",
      "\n",
      "\n",
      "Step: 16600\n",
      "loss: 0.0013\n",
      "grad_norm: 0.017598073929548264\n",
      "learning_rate: 0.0010418470418470417\n",
      "epoch: 2.3953823953823954\n",
      "\n",
      "\n",
      "Step: 16700\n",
      "loss: 0.0013\n",
      "grad_norm: 0.021584732457995415\n",
      "learning_rate: 0.0010360750360750362\n",
      "epoch: 2.40981240981241\n",
      "\n",
      "\n",
      "Step: 16800\n",
      "loss: 0.0015\n",
      "grad_norm: 0.01795676350593567\n",
      "learning_rate: 0.0010303030303030303\n",
      "epoch: 2.4242424242424243\n",
      "\n",
      "\n",
      "Step: 16900\n",
      "loss: 0.0015\n",
      "grad_norm: 0.015610981732606888\n",
      "learning_rate: 0.0010245310245310247\n",
      "epoch: 2.4386724386724388\n",
      "\n",
      "\n",
      "Step: 17000\n",
      "loss: 0.0014\n",
      "grad_norm: 0.020717982202768326\n",
      "learning_rate: 0.0010187590187590188\n",
      "epoch: 2.4531024531024532\n",
      "\n",
      "\n",
      "Step: 17100\n",
      "loss: 0.0016\n",
      "grad_norm: 0.009441889822483063\n",
      "learning_rate: 0.0010129870129870129\n",
      "epoch: 2.4675324675324677\n",
      "\n",
      "\n",
      "Step: 17200\n",
      "loss: 0.0013\n",
      "grad_norm: 0.018205828964710236\n",
      "learning_rate: 0.0010072150072150073\n",
      "epoch: 2.481962481962482\n",
      "\n",
      "\n",
      "Step: 17300\n",
      "loss: 0.0015\n",
      "grad_norm: 0.02011263184249401\n",
      "learning_rate: 0.0010014430014430014\n",
      "epoch: 2.496392496392496\n",
      "\n",
      "\n",
      "Step: 17400\n",
      "loss: 0.0014\n",
      "grad_norm: 0.008163858205080032\n",
      "learning_rate: 0.0009956709956709957\n",
      "epoch: 2.5108225108225106\n",
      "\n",
      "\n",
      "Step: 17500\n",
      "loss: 0.0013\n",
      "grad_norm: 0.01820097677409649\n",
      "learning_rate: 0.00098989898989899\n",
      "epoch: 2.525252525252525\n",
      "\n",
      "\n",
      "Step: 17600\n",
      "loss: 0.0012\n",
      "grad_norm: 0.02426372841000557\n",
      "learning_rate: 0.000984126984126984\n",
      "epoch: 2.5396825396825395\n",
      "\n",
      "\n",
      "Step: 17700\n",
      "loss: 0.0014\n",
      "grad_norm: 0.014575603418052197\n",
      "learning_rate: 0.0009783549783549783\n",
      "epoch: 2.554112554112554\n",
      "\n",
      "\n",
      "Step: 17800\n",
      "loss: 0.0013\n",
      "grad_norm: 0.013919312506914139\n",
      "learning_rate: 0.0009725829725829725\n",
      "epoch: 2.5685425685425685\n",
      "\n",
      "\n",
      "Step: 17900\n",
      "loss: 0.0012\n",
      "grad_norm: 0.03485242277383804\n",
      "learning_rate: 0.0009668109668109668\n",
      "epoch: 2.582972582972583\n",
      "\n",
      "\n",
      "Step: 18000\n",
      "loss: 0.0013\n",
      "grad_norm: 0.028811180964112282\n",
      "learning_rate: 0.0009610389610389611\n",
      "epoch: 2.5974025974025974\n",
      "\n",
      "\n",
      "Step: 18100\n",
      "loss: 0.0014\n",
      "grad_norm: 0.022473057731986046\n",
      "learning_rate: 0.0009552669552669552\n",
      "epoch: 2.611832611832612\n",
      "\n",
      "\n",
      "Step: 18200\n",
      "loss: 0.0012\n",
      "grad_norm: 0.007379247806966305\n",
      "learning_rate: 0.0009494949494949495\n",
      "epoch: 2.6262626262626263\n",
      "\n",
      "\n",
      "Step: 18300\n",
      "loss: 0.0013\n",
      "grad_norm: 0.016830937936902046\n",
      "learning_rate: 0.0009437229437229438\n",
      "epoch: 2.6406926406926408\n",
      "\n",
      "\n",
      "Step: 18400\n",
      "loss: 0.0013\n",
      "grad_norm: 0.021440839394927025\n",
      "learning_rate: 0.000937950937950938\n",
      "epoch: 2.655122655122655\n",
      "\n",
      "\n",
      "Step: 18500\n",
      "loss: 0.0013\n",
      "grad_norm: 0.0180678591132164\n",
      "learning_rate: 0.0009321789321789322\n",
      "epoch: 2.6695526695526697\n",
      "\n",
      "\n",
      "Step: 18600\n",
      "loss: 0.0013\n",
      "grad_norm: 0.020025677978992462\n",
      "learning_rate: 0.0009264069264069265\n",
      "epoch: 2.683982683982684\n",
      "\n",
      "\n",
      "Step: 18700\n",
      "loss: 0.0012\n",
      "grad_norm: 0.015254856087267399\n",
      "learning_rate: 0.0009206349206349207\n",
      "epoch: 2.6984126984126986\n",
      "\n",
      "\n",
      "Step: 18800\n",
      "loss: 0.0012\n",
      "grad_norm: 0.008822808042168617\n",
      "learning_rate: 0.0009148629148629148\n",
      "epoch: 2.712842712842713\n",
      "\n",
      "\n",
      "Step: 18900\n",
      "loss: 0.0013\n",
      "grad_norm: 0.010902263224124908\n",
      "learning_rate: 0.0009090909090909091\n",
      "epoch: 2.7272727272727275\n",
      "\n",
      "\n",
      "Step: 19000\n",
      "loss: 0.0014\n",
      "grad_norm: 0.015052489936351776\n",
      "learning_rate: 0.0009033189033189034\n",
      "epoch: 2.741702741702742\n",
      "\n",
      "\n",
      "Step: 19100\n",
      "loss: 0.0013\n",
      "grad_norm: 0.014473521150648594\n",
      "learning_rate: 0.0008975468975468975\n",
      "epoch: 2.756132756132756\n",
      "\n",
      "\n",
      "Step: 19200\n",
      "loss: 0.0013\n",
      "grad_norm: 0.011789695359766483\n",
      "learning_rate: 0.0008917748917748918\n",
      "epoch: 2.7705627705627704\n",
      "\n",
      "\n",
      "Step: 19300\n",
      "loss: 0.0014\n",
      "grad_norm: 0.00936283078044653\n",
      "learning_rate: 0.0008860028860028861\n",
      "epoch: 2.784992784992785\n",
      "\n",
      "\n",
      "Step: 19400\n",
      "loss: 0.0013\n",
      "grad_norm: 0.021069826558232307\n",
      "learning_rate: 0.0008802308802308802\n",
      "epoch: 2.7994227994227994\n",
      "\n",
      "\n",
      "Step: 19500\n",
      "loss: 0.0013\n",
      "grad_norm: 0.017490243539214134\n",
      "learning_rate: 0.0008744588744588745\n",
      "epoch: 2.813852813852814\n",
      "\n",
      "\n",
      "Step: 19600\n",
      "loss: 0.0012\n",
      "grad_norm: 0.01842525228857994\n",
      "learning_rate: 0.0008686868686868688\n",
      "epoch: 2.8282828282828283\n",
      "\n",
      "\n",
      "Step: 19700\n",
      "loss: 0.0013\n",
      "grad_norm: 0.012995827943086624\n",
      "learning_rate: 0.0008629148629148629\n",
      "epoch: 2.8427128427128427\n",
      "\n",
      "\n",
      "Step: 19800\n",
      "loss: 0.0012\n",
      "grad_norm: 0.015167132951319218\n",
      "learning_rate: 0.0008571428571428571\n",
      "epoch: 2.857142857142857\n",
      "\n",
      "\n",
      "Step: 19900\n",
      "loss: 0.0012\n",
      "grad_norm: 0.021046552807092667\n",
      "learning_rate: 0.0008513708513708514\n",
      "epoch: 2.8715728715728717\n",
      "\n",
      "\n",
      "Step: 20000\n",
      "loss: 0.0012\n",
      "grad_norm: 0.008345299400389194\n",
      "learning_rate: 0.0008455988455988456\n",
      "epoch: 2.886002886002886\n",
      "\n",
      "\n",
      "Step: 20100\n",
      "loss: 0.0012\n",
      "grad_norm: 0.013403918594121933\n",
      "learning_rate: 0.0008398268398268398\n",
      "epoch: 2.9004329004329006\n",
      "\n",
      "\n",
      "Step: 20200\n",
      "loss: 0.0012\n",
      "grad_norm: 0.026087529957294464\n",
      "learning_rate: 0.0008340548340548341\n",
      "epoch: 2.9148629148629146\n",
      "\n",
      "\n",
      "Step: 20300\n",
      "loss: 0.0013\n",
      "grad_norm: 0.005904992111027241\n",
      "learning_rate: 0.0008282828282828283\n",
      "epoch: 2.929292929292929\n",
      "\n",
      "\n",
      "Step: 20400\n",
      "loss: 0.0012\n",
      "grad_norm: 0.01141420193016529\n",
      "learning_rate: 0.0008225108225108225\n",
      "epoch: 2.9437229437229435\n",
      "\n",
      "\n",
      "Step: 20500\n",
      "loss: 0.0012\n",
      "grad_norm: 0.013037913478910923\n",
      "learning_rate: 0.0008167388167388168\n",
      "epoch: 2.958152958152958\n",
      "\n",
      "\n",
      "Step: 20600\n",
      "loss: 0.0013\n",
      "grad_norm: 0.012365885078907013\n",
      "learning_rate: 0.000810966810966811\n",
      "epoch: 2.9725829725829724\n",
      "\n",
      "\n",
      "Step: 20700\n",
      "loss: 0.0012\n",
      "grad_norm: 0.01817687228322029\n",
      "learning_rate: 0.0008051948051948052\n",
      "epoch: 2.987012987012987\n",
      "\n",
      "\n",
      "Step: 20790\n",
      "eval_loss: 0.0022603576071560383\n",
      "eval_runtime: 295.0772\n",
      "eval_samples_per_second: 322.068\n",
      "eval_steps_per_second: 5.033\n",
      "epoch: 3.0\n",
      "\n",
      "\n",
      "Step: 20800\n",
      "loss: 0.0011\n",
      "grad_norm: 0.008635593578219414\n",
      "learning_rate: 0.0007994227994227994\n",
      "epoch: 3.0014430014430014\n",
      "\n",
      "\n",
      "Step: 20900\n",
      "loss: 0.0011\n",
      "grad_norm: 0.012554462999105453\n",
      "learning_rate: 0.0007936507936507937\n",
      "epoch: 3.015873015873016\n",
      "\n",
      "\n",
      "Step: 21000\n",
      "loss: 0.001\n",
      "grad_norm: 0.010472806170582771\n",
      "learning_rate: 0.0007878787878787878\n",
      "epoch: 3.0303030303030303\n",
      "\n",
      "\n",
      "Step: 21100\n",
      "loss: 0.001\n",
      "grad_norm: 0.007811563089489937\n",
      "learning_rate: 0.0007821067821067821\n",
      "epoch: 3.0447330447330447\n",
      "\n",
      "\n",
      "Step: 21200\n",
      "loss: 0.001\n",
      "grad_norm: 0.006990022026002407\n",
      "learning_rate: 0.0007763347763347764\n",
      "epoch: 3.059163059163059\n",
      "\n",
      "\n",
      "Step: 21300\n",
      "loss: 0.001\n",
      "grad_norm: 0.0072758435271680355\n",
      "learning_rate: 0.0007705627705627706\n",
      "epoch: 3.0735930735930737\n",
      "\n",
      "\n",
      "Step: 21400\n",
      "loss: 0.001\n",
      "grad_norm: 0.010621110908687115\n",
      "learning_rate: 0.0007647907647907648\n",
      "epoch: 3.088023088023088\n",
      "\n",
      "\n",
      "Step: 21500\n",
      "loss: 0.001\n",
      "grad_norm: 0.008991962298750877\n",
      "learning_rate: 0.0007590187590187591\n",
      "epoch: 3.1024531024531026\n",
      "\n",
      "\n",
      "Step: 21600\n",
      "loss: 0.001\n",
      "grad_norm: 0.02804717607796192\n",
      "learning_rate: 0.0007532467532467533\n",
      "epoch: 3.116883116883117\n",
      "\n",
      "\n",
      "Step: 21700\n",
      "loss: 0.0011\n",
      "grad_norm: 0.020891645923256874\n",
      "learning_rate: 0.0007474747474747475\n",
      "epoch: 3.1313131313131315\n",
      "\n",
      "\n",
      "Step: 21800\n",
      "loss: 0.001\n",
      "grad_norm: 0.014742448925971985\n",
      "learning_rate: 0.0007417027417027418\n",
      "epoch: 3.145743145743146\n",
      "\n",
      "\n",
      "Step: 21900\n",
      "loss: 0.001\n",
      "grad_norm: 0.0072269015945494175\n",
      "learning_rate: 0.0007359307359307359\n",
      "epoch: 3.16017316017316\n",
      "\n",
      "\n",
      "Step: 22000\n",
      "loss: 0.0009\n",
      "grad_norm: 0.010150488466024399\n",
      "learning_rate: 0.0007301587301587301\n",
      "epoch: 3.1746031746031744\n",
      "\n",
      "\n",
      "Step: 22100\n",
      "loss: 0.0009\n",
      "grad_norm: 0.015060228295624256\n",
      "learning_rate: 0.0007243867243867244\n",
      "epoch: 3.189033189033189\n",
      "\n",
      "\n",
      "Step: 22200\n",
      "loss: 0.001\n",
      "grad_norm: 0.006872663740068674\n",
      "learning_rate: 0.0007186147186147186\n",
      "epoch: 3.2034632034632033\n",
      "\n",
      "\n",
      "Step: 22300\n",
      "loss: 0.001\n",
      "grad_norm: 0.019108081236481667\n",
      "learning_rate: 0.0007128427128427128\n",
      "epoch: 3.217893217893218\n",
      "\n",
      "\n",
      "Step: 22400\n",
      "loss: 0.001\n",
      "grad_norm: 0.009272883646190166\n",
      "learning_rate: 0.0007070707070707071\n",
      "epoch: 3.2323232323232323\n",
      "\n",
      "\n",
      "Step: 22500\n",
      "loss: 0.001\n",
      "grad_norm: 0.026190154254436493\n",
      "learning_rate: 0.0007012987012987013\n",
      "epoch: 3.2467532467532467\n",
      "\n",
      "\n",
      "Step: 22600\n",
      "loss: 0.001\n",
      "grad_norm: 0.008910524658858776\n",
      "learning_rate: 0.0006955266955266956\n",
      "epoch: 3.261183261183261\n",
      "\n",
      "\n",
      "Step: 22700\n",
      "loss: 0.0009\n",
      "grad_norm: 0.004109874367713928\n",
      "learning_rate: 0.0006897546897546898\n",
      "epoch: 3.2756132756132756\n",
      "\n",
      "\n",
      "Step: 22800\n",
      "loss: 0.001\n",
      "grad_norm: 0.014394240453839302\n",
      "learning_rate: 0.000683982683982684\n",
      "epoch: 3.29004329004329\n",
      "\n",
      "\n",
      "Step: 22900\n",
      "loss: 0.001\n",
      "grad_norm: 0.018630700185894966\n",
      "learning_rate: 0.0006782106782106783\n",
      "epoch: 3.3044733044733046\n",
      "\n",
      "\n",
      "Step: 23000\n",
      "loss: 0.001\n",
      "grad_norm: 0.006719525437802076\n",
      "learning_rate: 0.0006724386724386724\n",
      "epoch: 3.318903318903319\n",
      "\n",
      "\n",
      "Step: 23100\n",
      "loss: 0.001\n",
      "grad_norm: 0.016719911247491837\n",
      "learning_rate: 0.0006666666666666666\n",
      "epoch: 3.3333333333333335\n",
      "\n",
      "\n",
      "Step: 23200\n",
      "loss: 0.0009\n",
      "grad_norm: 0.006587706971913576\n",
      "learning_rate: 0.0006608946608946609\n",
      "epoch: 3.347763347763348\n",
      "\n",
      "\n",
      "Step: 23300\n",
      "loss: 0.001\n",
      "grad_norm: 0.009766953065991402\n",
      "learning_rate: 0.0006551226551226551\n",
      "epoch: 3.362193362193362\n",
      "\n",
      "\n",
      "Step: 23400\n",
      "loss: 0.0009\n",
      "grad_norm: 0.009031735360622406\n",
      "learning_rate: 0.0006493506493506494\n",
      "epoch: 3.3766233766233764\n",
      "\n",
      "\n",
      "Step: 23500\n",
      "loss: 0.001\n",
      "grad_norm: 0.0054207537323236465\n",
      "learning_rate: 0.0006435786435786436\n",
      "epoch: 3.391053391053391\n",
      "\n",
      "\n",
      "Step: 23600\n",
      "loss: 0.001\n",
      "grad_norm: 0.018581705167889595\n",
      "learning_rate: 0.0006378066378066378\n",
      "epoch: 3.4054834054834053\n",
      "\n",
      "\n",
      "Step: 23700\n",
      "loss: 0.001\n",
      "grad_norm: 0.02352827414870262\n",
      "learning_rate: 0.0006320346320346321\n",
      "epoch: 3.41991341991342\n",
      "\n",
      "\n",
      "Step: 23800\n",
      "loss: 0.0009\n",
      "grad_norm: 0.012536762282252312\n",
      "learning_rate: 0.0006262626262626263\n",
      "epoch: 3.4343434343434343\n",
      "\n",
      "\n",
      "Step: 23900\n",
      "loss: 0.001\n",
      "grad_norm: 0.009776518680155277\n",
      "learning_rate: 0.0006204906204906206\n",
      "epoch: 3.4487734487734487\n",
      "\n",
      "\n",
      "Step: 24000\n",
      "loss: 0.0009\n",
      "grad_norm: 0.005873249378055334\n",
      "learning_rate: 0.0006147186147186147\n",
      "epoch: 3.463203463203463\n",
      "\n",
      "\n",
      "Step: 24100\n",
      "loss: 0.001\n",
      "grad_norm: 0.002286490285769105\n",
      "learning_rate: 0.0006089466089466089\n",
      "epoch: 3.4776334776334776\n",
      "\n",
      "\n",
      "Step: 24200\n",
      "loss: 0.0009\n",
      "grad_norm: 0.011440376751124859\n",
      "learning_rate: 0.0006031746031746032\n",
      "epoch: 3.492063492063492\n",
      "\n",
      "\n",
      "Step: 24300\n",
      "loss: 0.0009\n",
      "grad_norm: 0.0025173090398311615\n",
      "learning_rate: 0.0005974025974025974\n",
      "epoch: 3.5064935064935066\n",
      "\n",
      "\n",
      "Step: 24400\n",
      "loss: 0.001\n",
      "grad_norm: 0.016398249194025993\n",
      "learning_rate: 0.0005916305916305916\n",
      "epoch: 3.520923520923521\n",
      "\n",
      "\n",
      "Step: 24500\n",
      "loss: 0.0009\n",
      "grad_norm: 0.02042902261018753\n",
      "learning_rate: 0.0005858585858585859\n",
      "epoch: 3.5353535353535355\n",
      "\n",
      "\n",
      "Step: 24600\n",
      "loss: 0.001\n",
      "grad_norm: 0.014284978620707989\n",
      "learning_rate: 0.0005800865800865801\n",
      "epoch: 3.54978354978355\n",
      "\n",
      "\n",
      "Step: 24700\n",
      "loss: 0.001\n",
      "grad_norm: 0.012226437218487263\n",
      "learning_rate: 0.0005743145743145743\n",
      "epoch: 3.5642135642135644\n",
      "\n",
      "\n",
      "Step: 24800\n",
      "loss: 0.0009\n",
      "grad_norm: 0.008415254764258862\n",
      "learning_rate: 0.0005685425685425686\n",
      "epoch: 3.578643578643579\n",
      "\n",
      "\n",
      "Step: 24900\n",
      "loss: 0.0009\n",
      "grad_norm: 0.006553787272423506\n",
      "learning_rate: 0.0005627705627705628\n",
      "epoch: 3.5930735930735933\n",
      "\n",
      "\n",
      "Step: 25000\n",
      "loss: 0.001\n",
      "grad_norm: 0.007442799862474203\n",
      "learning_rate: 0.000556998556998557\n",
      "epoch: 3.6075036075036078\n",
      "\n",
      "\n",
      "Step: 25100\n",
      "loss: 0.0009\n",
      "grad_norm: 0.005083709489554167\n",
      "learning_rate: 0.0005512265512265512\n",
      "epoch: 3.621933621933622\n",
      "\n",
      "\n",
      "Step: 25200\n",
      "loss: 0.0008\n",
      "grad_norm: 0.010250725783407688\n",
      "learning_rate: 0.0005454545454545455\n",
      "epoch: 3.6363636363636362\n",
      "\n",
      "\n",
      "Step: 25300\n",
      "loss: 0.0009\n",
      "grad_norm: 0.004542997106909752\n",
      "learning_rate: 0.0005396825396825396\n",
      "epoch: 3.6507936507936507\n",
      "\n",
      "\n",
      "Step: 25400\n",
      "loss: 0.0009\n",
      "grad_norm: 0.008155287243425846\n",
      "learning_rate: 0.0005339105339105339\n",
      "epoch: 3.665223665223665\n",
      "\n",
      "\n",
      "Step: 25500\n",
      "loss: 0.0009\n",
      "grad_norm: 0.007289387751370668\n",
      "learning_rate: 0.0005281385281385282\n",
      "epoch: 3.6796536796536796\n",
      "\n",
      "\n",
      "Step: 25600\n",
      "loss: 0.0009\n",
      "grad_norm: 0.01346281636506319\n",
      "learning_rate: 0.0005223665223665223\n",
      "epoch: 3.694083694083694\n",
      "\n",
      "\n",
      "Step: 25700\n",
      "loss: 0.001\n",
      "grad_norm: 0.010180816054344177\n",
      "learning_rate: 0.0005165945165945166\n",
      "epoch: 3.7085137085137085\n",
      "\n",
      "\n",
      "Step: 25800\n",
      "loss: 0.0009\n",
      "grad_norm: 0.019074654206633568\n",
      "learning_rate: 0.0005108225108225109\n",
      "epoch: 3.722943722943723\n",
      "\n",
      "\n",
      "Step: 25900\n",
      "loss: 0.0009\n",
      "grad_norm: 0.008857933804392815\n",
      "learning_rate: 0.000505050505050505\n",
      "epoch: 3.7373737373737375\n",
      "\n",
      "\n",
      "Step: 26000\n",
      "loss: 0.0008\n",
      "grad_norm: 0.008167939260601997\n",
      "learning_rate: 0.0004992784992784993\n",
      "epoch: 3.751803751803752\n",
      "\n",
      "\n",
      "Step: 26100\n",
      "loss: 0.0009\n",
      "grad_norm: 0.01034486759454012\n",
      "learning_rate: 0.0004935064935064935\n",
      "epoch: 3.7662337662337664\n",
      "\n",
      "\n",
      "Step: 26200\n",
      "loss: 0.0009\n",
      "grad_norm: 0.008669442497193813\n",
      "learning_rate: 0.00048773448773448776\n",
      "epoch: 3.7806637806637804\n",
      "\n",
      "\n",
      "Step: 26300\n",
      "loss: 0.0008\n",
      "grad_norm: 0.015846053138375282\n",
      "learning_rate: 0.000481962481962482\n",
      "epoch: 3.795093795093795\n",
      "\n",
      "\n",
      "Step: 26400\n",
      "loss: 0.0009\n",
      "grad_norm: 0.05216538533568382\n",
      "learning_rate: 0.0004761904761904762\n",
      "epoch: 3.8095238095238093\n",
      "\n",
      "\n",
      "Step: 26500\n",
      "loss: 0.0008\n",
      "grad_norm: 0.0074356188997626305\n",
      "learning_rate: 0.0004704184704184704\n",
      "epoch: 3.8239538239538238\n",
      "\n",
      "\n",
      "Step: 26600\n",
      "loss: 0.0008\n",
      "grad_norm: 0.008878632448613644\n",
      "learning_rate: 0.0004646464646464646\n",
      "epoch: 3.8383838383838382\n",
      "\n",
      "\n",
      "Step: 26700\n",
      "loss: 0.0009\n",
      "grad_norm: 0.006213321350514889\n",
      "learning_rate: 0.0004588744588744589\n",
      "epoch: 3.8528138528138527\n",
      "\n",
      "\n",
      "Step: 26800\n",
      "loss: 0.0008\n",
      "grad_norm: 0.00998495053499937\n",
      "learning_rate: 0.0004531024531024531\n",
      "epoch: 3.867243867243867\n",
      "\n",
      "\n",
      "Step: 26900\n",
      "loss: 0.0009\n",
      "grad_norm: 0.008023485541343689\n",
      "learning_rate: 0.0004473304473304474\n",
      "epoch: 3.8816738816738816\n",
      "\n",
      "\n",
      "Step: 27000\n",
      "loss: 0.0008\n",
      "grad_norm: 0.007475621532648802\n",
      "learning_rate: 0.00044155844155844155\n",
      "epoch: 3.896103896103896\n",
      "\n",
      "\n",
      "Step: 27100\n",
      "loss: 0.0009\n",
      "grad_norm: 0.013342251069843769\n",
      "learning_rate: 0.00043578643578643576\n",
      "epoch: 3.9105339105339105\n",
      "\n",
      "\n",
      "Step: 27200\n",
      "loss: 0.0008\n",
      "grad_norm: 0.010113852098584175\n",
      "learning_rate: 0.00043001443001443004\n",
      "epoch: 3.924963924963925\n",
      "\n",
      "\n",
      "Step: 27300\n",
      "loss: 0.0008\n",
      "grad_norm: 0.009136992506682873\n",
      "learning_rate: 0.00042424242424242425\n",
      "epoch: 3.9393939393939394\n",
      "\n",
      "\n",
      "Step: 27400\n",
      "loss: 0.0008\n",
      "grad_norm: 0.006220266688615084\n",
      "learning_rate: 0.0004184704184704185\n",
      "epoch: 3.953823953823954\n",
      "\n",
      "\n",
      "Step: 27500\n",
      "loss: 0.0008\n",
      "grad_norm: 0.009369680657982826\n",
      "learning_rate: 0.0004126984126984127\n",
      "epoch: 3.9682539682539684\n",
      "\n",
      "\n",
      "Step: 27600\n",
      "loss: 0.0009\n",
      "grad_norm: 0.0009238542406819761\n",
      "learning_rate: 0.0004069264069264069\n",
      "epoch: 3.982683982683983\n",
      "\n",
      "\n",
      "Step: 27700\n",
      "loss: 0.0009\n",
      "grad_norm: 0.018931251019239426\n",
      "learning_rate: 0.0004011544011544012\n",
      "epoch: 3.9971139971139973\n",
      "\n",
      "\n",
      "Step: 27720\n",
      "eval_loss: 0.0019877988379448652\n",
      "eval_runtime: 296.9294\n",
      "eval_samples_per_second: 320.059\n",
      "eval_steps_per_second: 5.001\n",
      "epoch: 4.0\n",
      "\n",
      "\n",
      "Step: 27800\n",
      "loss: 0.0007\n",
      "grad_norm: 0.011098803952336311\n",
      "learning_rate: 0.0003953823953823954\n",
      "epoch: 4.011544011544012\n",
      "\n",
      "\n",
      "Step: 27900\n",
      "loss: 0.0007\n",
      "grad_norm: 0.0051779248751699924\n",
      "learning_rate: 0.00038961038961038966\n",
      "epoch: 4.025974025974026\n",
      "\n",
      "\n",
      "Step: 28000\n",
      "loss: 0.0007\n",
      "grad_norm: 0.005803965497761965\n",
      "learning_rate: 0.00038383838383838383\n",
      "epoch: 4.040404040404041\n",
      "\n",
      "\n",
      "Step: 28100\n",
      "loss: 0.0007\n",
      "grad_norm: 0.009173109196126461\n",
      "learning_rate: 0.00037806637806637804\n",
      "epoch: 4.054834054834055\n",
      "\n",
      "\n",
      "Step: 28200\n",
      "loss: 0.0007\n",
      "grad_norm: 0.011011213064193726\n",
      "learning_rate: 0.0003722943722943723\n",
      "epoch: 4.06926406926407\n",
      "\n",
      "\n",
      "Step: 28300\n",
      "loss: 0.0007\n",
      "grad_norm: 0.0058517144061625\n",
      "learning_rate: 0.00036652236652236653\n",
      "epoch: 4.083694083694084\n",
      "\n",
      "\n",
      "Step: 28400\n",
      "loss: 0.0007\n",
      "grad_norm: 0.004218761809170246\n",
      "learning_rate: 0.00036075036075036075\n",
      "epoch: 4.0981240981240985\n",
      "\n",
      "\n",
      "Step: 28500\n",
      "loss: 0.0006\n",
      "grad_norm: 0.021190300583839417\n",
      "learning_rate: 0.000354978354978355\n",
      "epoch: 4.112554112554113\n",
      "\n",
      "\n",
      "Step: 28600\n",
      "loss: 0.0007\n",
      "grad_norm: 0.005947125609964132\n",
      "learning_rate: 0.0003492063492063492\n",
      "epoch: 4.1269841269841265\n",
      "\n",
      "\n",
      "Step: 28700\n",
      "loss: 0.0006\n",
      "grad_norm: 0.003098526271060109\n",
      "learning_rate: 0.00034343434343434346\n",
      "epoch: 4.141414141414141\n",
      "\n",
      "\n",
      "Step: 28800\n",
      "loss: 0.0006\n",
      "grad_norm: 0.006141568534076214\n",
      "learning_rate: 0.00033766233766233767\n",
      "epoch: 4.1558441558441555\n",
      "\n",
      "\n",
      "Step: 28900\n",
      "loss: 0.0006\n",
      "grad_norm: 0.003367580706253648\n",
      "learning_rate: 0.0003318903318903319\n",
      "epoch: 4.17027417027417\n",
      "\n",
      "\n",
      "Step: 29000\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0041016340255737305\n",
      "learning_rate: 0.00032611832611832616\n",
      "epoch: 4.184704184704184\n",
      "\n",
      "\n",
      "Step: 29100\n",
      "loss: 0.0007\n",
      "grad_norm: 0.0016260590637102723\n",
      "learning_rate: 0.0003203463203463203\n",
      "epoch: 4.199134199134199\n",
      "\n",
      "\n",
      "Step: 29200\n",
      "loss: 0.0006\n",
      "grad_norm: 0.006933126132935286\n",
      "learning_rate: 0.00031457431457431454\n",
      "epoch: 4.213564213564213\n",
      "\n",
      "\n",
      "Step: 29300\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0034482514020055532\n",
      "learning_rate: 0.0003088023088023088\n",
      "epoch: 4.227994227994228\n",
      "\n",
      "\n",
      "Step: 29400\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0026344775687903166\n",
      "learning_rate: 0.00030303030303030303\n",
      "epoch: 4.242424242424242\n",
      "\n",
      "\n",
      "Step: 29500\n",
      "loss: 0.0006\n",
      "grad_norm: 0.006246400531381369\n",
      "learning_rate: 0.0002972582972582973\n",
      "epoch: 4.256854256854257\n",
      "\n",
      "\n",
      "Step: 29600\n",
      "loss: 0.0007\n",
      "grad_norm: 0.011005865409970284\n",
      "learning_rate: 0.00029148629148629146\n",
      "epoch: 4.271284271284271\n",
      "\n",
      "\n",
      "Step: 29700\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0016703208675608039\n",
      "learning_rate: 0.0002857142857142857\n",
      "epoch: 4.285714285714286\n",
      "\n",
      "\n",
      "Step: 29800\n",
      "loss: 0.0007\n",
      "grad_norm: 0.007578236050903797\n",
      "learning_rate: 0.00027994227994227995\n",
      "epoch: 4.3001443001443\n",
      "\n",
      "\n",
      "Step: 29900\n",
      "loss: 0.0006\n",
      "grad_norm: 0.01374048087745905\n",
      "learning_rate: 0.00027417027417027417\n",
      "epoch: 4.3145743145743145\n",
      "\n",
      "\n",
      "Step: 30000\n",
      "loss: 0.0006\n",
      "grad_norm: 0.005644221790134907\n",
      "learning_rate: 0.00026839826839826844\n",
      "epoch: 4.329004329004329\n",
      "\n",
      "\n",
      "Step: 30100\n",
      "loss: 0.0006\n",
      "grad_norm: 0.01669754460453987\n",
      "learning_rate: 0.00026262626262626266\n",
      "epoch: 4.343434343434343\n",
      "\n",
      "\n",
      "Step: 30200\n",
      "loss: 0.0006\n",
      "grad_norm: 0.009312191046774387\n",
      "learning_rate: 0.0002568542568542568\n",
      "epoch: 4.357864357864358\n",
      "\n",
      "\n",
      "Step: 30300\n",
      "loss: 0.0006\n",
      "grad_norm: 0.023141298443078995\n",
      "learning_rate: 0.0002510822510822511\n",
      "epoch: 4.372294372294372\n",
      "\n",
      "\n",
      "Step: 30400\n",
      "loss: 0.0007\n",
      "grad_norm: 0.004210569430142641\n",
      "learning_rate: 0.0002453102453102453\n",
      "epoch: 4.386724386724387\n",
      "\n",
      "\n",
      "Step: 30500\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0053713819943368435\n",
      "learning_rate: 0.00023953823953823955\n",
      "epoch: 4.401154401154401\n",
      "\n",
      "\n",
      "Step: 30600\n",
      "loss: 0.0006\n",
      "grad_norm: 0.005776761099696159\n",
      "learning_rate: 0.00023376623376623377\n",
      "epoch: 4.415584415584416\n",
      "\n",
      "\n",
      "Step: 30700\n",
      "loss: 0.0007\n",
      "grad_norm: 0.003664168529212475\n",
      "learning_rate: 0.00022799422799422802\n",
      "epoch: 4.43001443001443\n",
      "\n",
      "\n",
      "Step: 30800\n",
      "loss: 0.0006\n",
      "grad_norm: 0.003559261094778776\n",
      "learning_rate: 0.0002222222222222222\n",
      "epoch: 4.444444444444445\n",
      "\n",
      "\n",
      "Step: 30900\n",
      "loss: 0.0007\n",
      "grad_norm: 0.004017433151602745\n",
      "learning_rate: 0.00021645021645021645\n",
      "epoch: 4.458874458874459\n",
      "\n",
      "\n",
      "Step: 31000\n",
      "loss: 0.0006\n",
      "grad_norm: 0.03287579491734505\n",
      "learning_rate: 0.0002106782106782107\n",
      "epoch: 4.473304473304474\n",
      "\n",
      "\n",
      "Step: 31100\n",
      "loss: 0.0006\n",
      "grad_norm: 0.011767353862524033\n",
      "learning_rate: 0.0002049062049062049\n",
      "epoch: 4.487734487734488\n",
      "\n",
      "\n",
      "Step: 31200\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0020107959862798452\n",
      "learning_rate: 0.00019913419913419913\n",
      "epoch: 4.5021645021645025\n",
      "\n",
      "\n",
      "Step: 31300\n",
      "loss: 0.0006\n",
      "grad_norm: 0.002751715946942568\n",
      "learning_rate: 0.00019336219336219337\n",
      "epoch: 4.516594516594517\n",
      "\n",
      "\n",
      "Step: 31400\n",
      "loss: 0.0007\n",
      "grad_norm: 0.007688471581786871\n",
      "learning_rate: 0.0001875901875901876\n",
      "epoch: 4.531024531024531\n",
      "\n",
      "\n",
      "Step: 31500\n",
      "loss: 0.0006\n",
      "grad_norm: 0.009705628268420696\n",
      "learning_rate: 0.00018181818181818183\n",
      "epoch: 4.545454545454545\n",
      "\n",
      "\n",
      "Step: 31600\n",
      "loss: 0.0006\n",
      "grad_norm: 0.007455066777765751\n",
      "learning_rate: 0.00017604617604617602\n",
      "epoch: 4.55988455988456\n",
      "\n",
      "\n",
      "Step: 31700\n",
      "loss: 0.0006\n",
      "grad_norm: 0.017658403143286705\n",
      "learning_rate: 0.00017027417027417027\n",
      "epoch: 4.574314574314574\n",
      "\n",
      "\n",
      "Step: 31800\n",
      "loss: 0.0006\n",
      "grad_norm: 0.00623747706413269\n",
      "learning_rate: 0.0001645021645021645\n",
      "epoch: 4.588744588744589\n",
      "\n",
      "\n",
      "Step: 31900\n",
      "loss: 0.0006\n",
      "grad_norm: 0.00411158287897706\n",
      "learning_rate: 0.00015873015873015873\n",
      "epoch: 4.603174603174603\n",
      "\n",
      "\n",
      "Step: 32000\n",
      "loss: 0.0006\n",
      "grad_norm: 0.012206184677779675\n",
      "learning_rate: 0.00015295815295815297\n",
      "epoch: 4.617604617604617\n",
      "\n",
      "\n",
      "Step: 32100\n",
      "loss: 0.0006\n",
      "grad_norm: 0.01761997863650322\n",
      "learning_rate: 0.0001471861471861472\n",
      "epoch: 4.632034632034632\n",
      "\n",
      "\n",
      "Step: 32200\n",
      "loss: 0.0007\n",
      "grad_norm: 0.005029148887842894\n",
      "learning_rate: 0.0001414141414141414\n",
      "epoch: 4.646464646464646\n",
      "\n",
      "\n",
      "Step: 32300\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0062339818105101585\n",
      "learning_rate: 0.00013564213564213565\n",
      "epoch: 4.660894660894661\n",
      "\n",
      "\n",
      "Step: 32400\n",
      "loss: 0.0006\n",
      "grad_norm: 0.02085191197693348\n",
      "learning_rate: 0.00012987012987012987\n",
      "epoch: 4.675324675324675\n",
      "\n",
      "\n",
      "Step: 32500\n",
      "loss: 0.0006\n",
      "grad_norm: 0.00319981318898499\n",
      "learning_rate: 0.0001240981240981241\n",
      "epoch: 4.68975468975469\n",
      "\n",
      "\n",
      "Step: 32600\n",
      "loss: 0.0006\n",
      "grad_norm: 0.027175256982445717\n",
      "learning_rate: 0.00011832611832611832\n",
      "epoch: 4.704184704184704\n",
      "\n",
      "\n",
      "Step: 32700\n",
      "loss: 0.0005\n",
      "grad_norm: 0.011258788406848907\n",
      "learning_rate: 0.00011255411255411256\n",
      "epoch: 4.7186147186147185\n",
      "\n",
      "\n",
      "Step: 32800\n",
      "loss: 0.0006\n",
      "grad_norm: 0.003484065644443035\n",
      "learning_rate: 0.00010678210678210678\n",
      "epoch: 4.733044733044733\n",
      "\n",
      "\n",
      "Step: 32900\n",
      "loss: 0.0006\n",
      "grad_norm: 0.004912802018225193\n",
      "learning_rate: 0.00010101010101010101\n",
      "epoch: 4.747474747474747\n",
      "\n",
      "\n",
      "Step: 33000\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0037979590706527233\n",
      "learning_rate: 9.523809523809524e-05\n",
      "epoch: 4.761904761904762\n",
      "\n",
      "\n",
      "Step: 33100\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0035078488290309906\n",
      "learning_rate: 8.946608946608947e-05\n",
      "epoch: 4.776334776334776\n",
      "\n",
      "\n",
      "Step: 33200\n",
      "loss: 0.0005\n",
      "grad_norm: 0.005024380050599575\n",
      "learning_rate: 8.36940836940837e-05\n",
      "epoch: 4.790764790764791\n",
      "\n",
      "\n",
      "Step: 33300\n",
      "loss: 0.0006\n",
      "grad_norm: 0.00506164925172925\n",
      "learning_rate: 7.792207792207792e-05\n",
      "epoch: 4.805194805194805\n",
      "\n",
      "\n",
      "Step: 33400\n",
      "loss: 0.0005\n",
      "grad_norm: 0.005613880231976509\n",
      "learning_rate: 7.215007215007215e-05\n",
      "epoch: 4.81962481962482\n",
      "\n",
      "\n",
      "Step: 33500\n",
      "loss: 0.0005\n",
      "grad_norm: 0.003950710874050856\n",
      "learning_rate: 6.637806637806638e-05\n",
      "epoch: 4.834054834054834\n",
      "\n",
      "\n",
      "Step: 33600\n",
      "loss: 0.0006\n",
      "grad_norm: 0.004266309551894665\n",
      "learning_rate: 6.060606060606061e-05\n",
      "epoch: 4.848484848484849\n",
      "\n",
      "\n",
      "Step: 33700\n",
      "loss: 0.0006\n",
      "grad_norm: 0.00767603749409318\n",
      "learning_rate: 5.4834054834054835e-05\n",
      "epoch: 4.862914862914863\n",
      "\n",
      "\n",
      "Step: 33800\n",
      "loss: 0.0006\n",
      "grad_norm: 0.011429136618971825\n",
      "learning_rate: 4.9062049062049066e-05\n",
      "epoch: 4.8773448773448775\n",
      "\n",
      "\n",
      "Step: 33900\n",
      "loss: 0.0006\n",
      "grad_norm: 0.007881948724389076\n",
      "learning_rate: 4.329004329004329e-05\n",
      "epoch: 4.891774891774892\n",
      "\n",
      "\n",
      "Step: 34000\n",
      "loss: 0.0005\n",
      "grad_norm: 0.002487692516297102\n",
      "learning_rate: 3.751803751803752e-05\n",
      "epoch: 4.9062049062049065\n",
      "\n",
      "\n",
      "Step: 34100\n",
      "loss: 0.0006\n",
      "grad_norm: 0.0057491883635520935\n",
      "learning_rate: 3.1746031746031745e-05\n",
      "epoch: 4.920634920634921\n",
      "\n",
      "\n",
      "Step: 34200\n",
      "loss: 0.0005\n",
      "grad_norm: 0.012132074683904648\n",
      "learning_rate: 2.5974025974025975e-05\n",
      "epoch: 4.935064935064935\n",
      "\n",
      "\n",
      "Step: 34300\n",
      "loss: 0.0005\n",
      "grad_norm: 0.008067548274993896\n",
      "learning_rate: 2.0202020202020203e-05\n",
      "epoch: 4.94949494949495\n",
      "\n",
      "\n",
      "Step: 34400\n",
      "loss: 0.0005\n",
      "grad_norm: 0.010193025693297386\n",
      "learning_rate: 1.443001443001443e-05\n",
      "epoch: 4.963924963924964\n",
      "\n",
      "\n",
      "Step: 34500\n",
      "loss: 0.0005\n",
      "grad_norm: 0.0023526842705905437\n",
      "learning_rate: 8.658008658008659e-06\n",
      "epoch: 4.978354978354979\n",
      "\n",
      "\n",
      "Step: 34600\n",
      "loss: 0.0005\n",
      "grad_norm: 0.0010612561600282788\n",
      "learning_rate: 2.886002886002886e-06\n",
      "epoch: 4.992784992784992\n",
      "\n",
      "\n",
      "Step: 34650\n",
      "eval_loss: 0.0020253544207662344\n",
      "eval_runtime: 298.2298\n",
      "eval_samples_per_second: 318.664\n",
      "eval_steps_per_second: 4.979\n",
      "epoch: 5.0\n",
      "\n",
      "\n",
      "Step: 34650\n",
      "train_runtime: 21567.8275\n",
      "train_samples_per_second: 102.815\n",
      "train_steps_per_second: 1.607\n",
      "total_flos: 7.502994201378816e+16\n",
      "train_loss: 0.0014088857105649566\n",
      "epoch: 5.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34650, training_loss=0.0014088857105649566, metrics={'train_runtime': 21567.8275, 'train_samples_per_second': 102.815, 'train_steps_per_second': 1.607, 'total_flos': 7.502994201378816e+16, 'train_loss': 0.0014088857105649566, 'epoch': 5.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up training arguments and custom callback\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=4,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            print(f\"Step: {state.global_step}\")\n",
    "            for key, value in logs.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "# Create and train the model using the Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    callbacks=[CustomCallback()]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ae87d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T13:53:09.535911Z",
     "iopub.status.busy": "2024-09-07T13:53:09.535090Z",
     "iopub.status.idle": "2024-09-07T13:58:07.160119Z",
     "shell.execute_reply": "2024-09-07T13:58:07.158113Z"
    },
    "papermill": {
     "duration": 297.670799,
     "end_time": "2024-09-07T13:58:07.162771",
     "exception": false,
     "start_time": "2024-09-07T13:53:09.491972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1485' max='1485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1485/1485 04:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 34650\n",
      "eval_loss: 0.0020253544207662344\n",
      "eval_runtime: 297.6141\n",
      "eval_samples_per_second: 319.323\n",
      "eval_steps_per_second: 4.99\n",
      "epoch: 5.0\n",
      "\n",
      "\n",
      "Validation Loss: 0.0020253544207662344\n"
     ]
    }
   ],
   "source": [
    "val_results = trainer.evaluate(eval_dataset=tokenized_datasets['validation'])\n",
    "print(f\"Validation Loss: {val_results['eval_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98008410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T13:58:07.253629Z",
     "iopub.status.busy": "2024-09-07T13:58:07.253198Z",
     "iopub.status.idle": "2024-09-07T13:58:07.817693Z",
     "shell.execute_reply": "2024-09-07T13:58:07.816681Z"
    },
    "papermill": {
     "duration": 0.61148,
     "end_time": "2024-09-07T13:58:07.820004",
     "exception": false,
     "start_time": "2024-09-07T13:58:07.208524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_t5_1000dp/tokenizer_config.json',\n",
       " './fine_tuned_t5_1000dp/special_tokens_map.json',\n",
       " './fine_tuned_t5_1000dp/spiece.model',\n",
       " './fine_tuned_t5_1000dp/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./fine_tuned_t5_1000dp')\n",
    "tokenizer.save_pretrained('./fine_tuned_t5_1000dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21fbe9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T13:58:07.908000Z",
     "iopub.status.busy": "2024-09-07T13:58:07.907607Z",
     "iopub.status.idle": "2024-09-07T13:58:07.924125Z",
     "shell.execute_reply": "2024-09-07T13:58:07.923173Z"
    },
    "papermill": {
     "duration": 0.062533,
     "end_time": "2024-09-07T13:58:07.926067",
     "exception": false,
     "start_time": "2024-09-07T13:58:07.863534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define functions for prediction and text processing\n",
    "def generate_text(inputs):\n",
    "    inputs = tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=352)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=128)\n",
    "    \n",
    "    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return generated_texts\n",
    "\n",
    "def extract_details(text):\n",
    "    pattern = r'details_Brand: (.*?) L0_category: (.*?) L1_category: (.*?) L2_category: (.*?) L3_category: (.*?) L4_category: (.*)'\n",
    "    match = re.match(pattern, text)\n",
    "    if match:\n",
    "        return tuple(item if item is not None else 'na' for item in match.groups())\n",
    "    return 'na', 'na', 'na', 'na', 'na', 'na'\n",
    "\n",
    "def clean_repeated_patterns(text):\n",
    "    cleaned_data = text.split(' L4_category')[0] \n",
    "    return cleaned_data\n",
    "\n",
    "# Define the function to evaluate predictions\n",
    "def evaluate_predictions(generated_details, target_details):\n",
    "    generated_dict = {i: [] for i in range(6)}\n",
    "    target_dict = {i: [] for i in range(6)}\n",
    "\n",
    "    for gen, tar in zip(generated_details, target_details):\n",
    "        for i in range(6):\n",
    "            generated_dict[i].append(gen[i])\n",
    "            target_dict[i].append(tar[i])\n",
    "\n",
    "    # Clean repeated patterns in L4_category\n",
    "    generated_dict[5] = [clean_repeated_patterns(text) for text in generated_dict[5]]\n",
    "\n",
    "    categories = ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "    results = {category: {metric: 0 for metric in metrics} for category in categories}\n",
    "\n",
    "    for i, category in enumerate(categories):\n",
    "        print('Current Category: ', category)\n",
    "        y_true = target_dict[i]\n",
    "        y_pred = generated_dict[i]\n",
    "        \n",
    "        results[category]['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "        results[category]['precision'] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        results[category]['recall'] = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        results[category]['f1'] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    for category, metrics in results.items():\n",
    "        print(f\"{category}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25dba3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T13:58:08.016512Z",
     "iopub.status.busy": "2024-09-07T13:58:08.016109Z",
     "iopub.status.idle": "2024-09-07T13:58:08.020931Z",
     "shell.execute_reply": "2024-09-07T13:58:08.019887Z"
    },
    "papermill": {
     "duration": 0.052562,
     "end_time": "2024-09-07T13:58:08.022966",
     "exception": false,
     "start_time": "2024-09-07T13:58:07.970404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7214cda2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T13:58:08.113376Z",
     "iopub.status.busy": "2024-09-07T13:58:08.112979Z",
     "iopub.status.idle": "2024-09-07T13:58:10.229291Z",
     "shell.execute_reply": "2024-09-07T13:58:10.228328Z"
    },
    "papermill": {
     "duration": 2.164232,
     "end_time": "2024-09-07T13:58:10.231775",
     "exception": false,
     "start_time": "2024-09-07T13:58:08.067543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    merged = {}\n",
    "    return data.apply(lambda row: f\"title: {row['title']} store: {row['store']} details_Manufacturer: {row['details_Manufacturer']}\", axis=1).to_list()\n",
    "\n",
    "test_dataset = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafc8eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T13:58:10.321895Z",
     "iopub.status.busy": "2024-09-07T13:58:10.321512Z",
     "iopub.status.idle": "2024-09-07T15:11:47.201108Z",
     "shell.execute_reply": "2024-09-07T15:11:47.199803Z"
    },
    "papermill": {
     "duration": 4416.92849,
     "end_time": "2024-09-07T15:11:47.204022",
     "exception": false,
     "start_time": "2024-09-07T13:58:10.275532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2970/2970 [1:13:36<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated info extracted.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "generated_details = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_dataset), batch_size), desc=\"Processing test data\"):\n",
    "    batch_inputs = test_dataset[i:i+batch_size]\n",
    "    \n",
    "    generated_texts = generate_text(batch_inputs)\n",
    "    \n",
    "    for generated_text in generated_texts:\n",
    "        generated_details.append(extract_details(generated_text))\n",
    "\n",
    "print('Generated info extracted.............')\n",
    "\n",
    "# Save the predictions to a DataFrame and then to a CSV file\n",
    "# predictions_df = pd.DataFrame(generated_details, columns=['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category'])\n",
    "# predictions_df['indoml_id'] = test_data['indoml_id'].iloc[:len(generated_details)]\n",
    "# predictions_df.to_csv('test_predictions.csv', index=False)\n",
    "# print(\"Predictions saved to 'test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9324dfc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T15:11:47.901551Z",
     "iopub.status.busy": "2024-09-07T15:11:47.900395Z",
     "iopub.status.idle": "2024-09-07T15:11:49.066277Z",
     "shell.execute_reply": "2024-09-07T15:11:49.065101Z"
    },
    "papermill": {
     "duration": 1.559602,
     "end_time": "2024-09-07T15:11:49.069530",
     "exception": false,
     "start_time": "2024-09-07T15:11:47.509928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "categories = ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n",
    "\n",
    "with open('attribute_test_Sneh.predict', 'w') as file:\n",
    "\n",
    "    for indoml_id, details in enumerate(generated_details):\n",
    "        result = {\"indoml_id\": indoml_id}\n",
    "        for category, value in zip(categories, details):\n",
    "            result[category] = value\n",
    "        \n",
    "        file.write(json.dumps(result) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fd69b",
   "metadata": {
    "papermill": {
     "duration": 0.308537,
     "end_time": "2024-09-07T15:11:49.699685",
     "exception": false,
     "start_time": "2024-09-07T15:11:49.391148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58767cd4",
   "metadata": {
    "papermill": {
     "duration": 0.313207,
     "end_time": "2024-09-07T15:11:50.319619",
     "exception": false,
     "start_time": "2024-09-07T15:11:50.006412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8e5e5",
   "metadata": {
    "papermill": {
     "duration": 0.318803,
     "end_time": "2024-09-07T15:11:50.948074",
     "exception": false,
     "start_time": "2024-09-07T15:11:50.629271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5578122,
     "sourceId": 9223518,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5609563,
     "sourceId": 9269572,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5611960,
     "sourceId": 9273033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5614177,
     "sourceId": 9276084,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26779.679484,
   "end_time": "2024-09-07T15:11:54.105830",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-07T07:45:34.426346",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1a11b084875a4840a64bce5aa7f78859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a6c305f2edb4143a4c4d9ccd0cdeb29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34950f02c71b41a485051c5bc52021e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd9aba7e73f44e9fa295408381ff410d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_95a6544c428e4d00bd9cad7a79ea5048",
       "value": "â€‡95035/95035â€‡[01:14&lt;00:00,â€‡1310.42â€‡examples/s]"
      }
     },
     "39662713b89543c7ab0e7dbc07ae5ae8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "59f1b90a71104c8cba209846b8ab374f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d2f4d55dc154247a690c3f3dc247327": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "635391858b4e4d5ab01639686cdd8702": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6696e615701a40a8b90d4396097e7807": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67704b7eda60463fbf3cac4a32ef742b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_93ea98c31adc4b5984cb9f84668c1e0b",
        "IPY_MODEL_768ddbbaed15412b9c491d1d1fd48174",
        "IPY_MODEL_a45e001c3d2a4471b0239fab70f62698"
       ],
       "layout": "IPY_MODEL_bde0411a716c4f83bd646e6f713c9357"
      }
     },
     "768ddbbaed15412b9c491d1d1fd48174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59f1b90a71104c8cba209846b8ab374f",
       "max": 443499.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_39662713b89543c7ab0e7dbc07ae5ae8",
       "value": 443499.0
      }
     },
     "7d49478c59e1499bbdc523b38906e06f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_966f8104e6e1439685525280c52333e2",
       "max": 95035.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1a11b084875a4840a64bce5aa7f78859",
       "value": 95035.0
      }
     },
     "93ea98c31adc4b5984cb9f84668c1e0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d2f4d55dc154247a690c3f3dc247327",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_fbbf3cda16294d58bba3e32a9744357e",
       "value": "Map:â€‡100%"
      }
     },
     "95a6544c428e4d00bd9cad7a79ea5048": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "966f8104e6e1439685525280c52333e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a45e001c3d2a4471b0239fab70f62698": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2a6c305f2edb4143a4c4d9ccd0cdeb29",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6696e615701a40a8b90d4396097e7807",
       "value": "â€‡443499/443499â€‡[05:38&lt;00:00,â€‡1291.81â€‡examples/s]"
      }
     },
     "aa088a3e9e0f4849a32e072d537135a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b4e3c7cee9de4de68556dbbc1584d458": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_635391858b4e4d5ab01639686cdd8702",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_aa088a3e9e0f4849a32e072d537135a1",
       "value": "Map:â€‡100%"
      }
     },
     "bde0411a716c4f83bd646e6f713c9357": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd9aba7e73f44e9fa295408381ff410d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "daa3f0b23566477cbb768b7e75f124f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8a556bd89b64d08bdb271f6cfbf464c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b4e3c7cee9de4de68556dbbc1584d458",
        "IPY_MODEL_7d49478c59e1499bbdc523b38906e06f",
        "IPY_MODEL_34950f02c71b41a485051c5bc52021e8"
       ],
       "layout": "IPY_MODEL_daa3f0b23566477cbb768b7e75f124f2"
      }
     },
     "fbbf3cda16294d58bba3e32a9744357e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
